{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestFeatures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_4FxfJIzHp"
      },
      "source": [
        "### **Импорт библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DDIGZI6IRLv",
        "outputId": "5f461389-6612-435e-bfbf-d5a6fc5c6c64"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g1759rCIxzC",
        "outputId": "1934a3f2-33f4-490c-f62f-30d8e8aa4012"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install sktime\n",
        "!pip install tqdm\n",
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.26.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: sktime in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.37.0)\n",
            "Requirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.51.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.24.2)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (0.34.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (2.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n",
            "Requirement already satisfied: DAWG>=0.8 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoDyTCGrJOmT",
        "outputId": "5eeeee88-7051-40c5-a131-94b73e87b245"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from sktime.transformations.panel.rocket import MiniRocket\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn9Yyc2cJ_EH"
      },
      "source": [
        "### **Считываем и смотрим на данные**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3wswvEKKtB"
      },
      "source": [
        "labled_train_data = pd.read_csv('/content/drive/MyDrive/labled_train_data.c sv', comment='#', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "labled_train_comments = pd.read_csv('/content/drive/MyDrive/labled_train_comments.csv', comment='#', sep='\\t').drop('Unnamed: 0', axis=1)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujZ8p_kuW4Co"
      },
      "source": [
        "### **Модель**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k6gy6dYqcdS"
      },
      "source": [
        "X, y = labled_train_data[labled_train_data.columns[:-1]], labled_train_data['is_aggressive']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wZyoWUU_IA"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.model = None\n",
        "    self.aggressive_words = {'verb': set(), 'adj': set(), 'all_words': set(), 'noun': set()}\n",
        "    self.morph_analyzer = MorphAnalyzer()\n",
        "\n",
        "  # возвращает нормальную форму слова и его тэг(характеристики слова)\n",
        "  def lemmatize_and_word_class(self, word):\n",
        "      w = self.morph_analyzer.parse(word)[0]\n",
        "      return w.normal_form, w.tag\n",
        "\n",
        "  # добавляет слова в словарь агрессивных слов\n",
        "  def make_agressive_vocab(self, X, y):\n",
        "    stop_words = set(stopwords.words('russian')) # стоп-слова из nltk\n",
        "    dataset = X.join(y).copy()\n",
        "    for row in dataset.itertuples(): # перебираем все строки в датасете\n",
        "      if getattr(row, 'is_aggressive') == 1 and getattr(row, 'comment'):\n",
        "        words = [self.lemmatize_and_word_class(re.sub(r'\\W', '', word)) for word in getattr(row, 'comment').split(' ')]\n",
        "        for word in words:\n",
        "          if word[0] not in stop_words:\n",
        "            if 'VERB' in word[1]:\n",
        "              self.aggressive_words['verb'].add(word[0])\n",
        "            elif 'ADJF' in word[1] or 'ADJS' in word[1]:\n",
        "              self.aggressive_words['adj'].add(word[0])\n",
        "            elif 'NOUN' in word[1]:\n",
        "              self.aggressive_words['noun'].add(word[0])\n",
        "            self.aggressive_words['all_words'].add(word[0])\n",
        "\n",
        "\n",
        "  # делаем NLP фичи на основе сгенерированного словаря\n",
        "  def NLP_feature_extract(self, X, y=None):\n",
        "\n",
        "    morph_analyzer = MorphAnalyzer()\n",
        "    stop_words = set(stopwords.words('russian')) # стоп-слова из nltk\n",
        "    agg_verbs_rate = [] # глаголы\n",
        "    agg_adjs_rate = [] # прилагательные\n",
        "    agg_nouns_rate = []\n",
        "    for row in X.itertuples(): # перебираем все строки в датасете\n",
        "      if getattr(row, 'comment'):\n",
        "        words = [self.lemmatize_and_word_class(re.sub(r'\\W', '', word)) for word in getattr(row, 'comment').split(' ')]\n",
        "        words_verb = [word[0] for word in words if 'VERB' in word[1] and word[0] not in stop_words]\n",
        "        words_adj = [word[0] for word in words if ('ADJF' in word[1] or 'ADJS' in word[1]) and word[0] not in stop_words]\n",
        "        words_noun = [word[0] for word in words if 'NOUN' in word[1] and word[0] not in stop_words]\n",
        "        if len(words_verb) > 0:\n",
        "          agg_verbs_rate.append(len(set(words_verb) & self.aggressive_words['verb']) / len(words_verb))\n",
        "        else:\n",
        "          agg_verbs_rate.append(0)\n",
        "        if len(words_adj) > 0:\n",
        "          agg_adjs_rate.append(len(set(words_adj) & self.aggressive_words['adj']) / len(words_adj))\n",
        "        else:\n",
        "          agg_adjs_rate.append(0)\n",
        "        if len(words_noun) > 0:\n",
        "          agg_nouns_rate.append(len(set(words_noun) & self.aggressive_words['noun']) / len(words_noun))\n",
        "        else:\n",
        "          agg_nouns_rate.append(0)\n",
        "    return agg_verbs_rate, agg_adjs_rate, agg_nouns_rate\n",
        "\n",
        "  # отбор фичей\n",
        "  def features(self, X):\n",
        "    data = X.copy()\n",
        "    agg_verbs_rate, agg_adjs_rate, agg_nouns_rate = self.NLP_feature_extract(data)\n",
        "    data['agg_verbs_rate'] = agg_verbs_rate\n",
        "    data['agg_adjs_rate'] = agg_adjs_rate\n",
        "    data['agg_nouns_rate'] = agg_nouns_rate\n",
        "    feature_list = ['arrived_distance', 'arrived_duration', 'distance', 'duration', 'from_latitude', 'from_longitude', 'to_latitude', 'to_longitude', 'client_rate_ride', 'client_rides_cnt', \n",
        "                    'driver_rides_cnt', 'agg_verbs_rate', 'agg_adjs_rate', 'agg_nouns_rate']\n",
        "    for feature in feature_list:\n",
        "      data = data.fillna({feature: data[feature].mean()})\n",
        "    return data[feature_list]\n",
        "\n",
        "  # кросс-валидация и предикт на тесте\n",
        "  def train_eval(self, X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    self.make_agressive_vocab(X_train, y_train)\n",
        "\n",
        "    self.model = LogisticRegression(random_state=42)\n",
        "\n",
        "    cv_score = cross_val_score(self.model, self.features(X_train), y_train, cv=5, scoring='roc_auc')\n",
        "    print(f\"CV_mean: {np.mean(cv_score)}, CV_std: {np.std(cv_score)}\")\n",
        "\n",
        "    self.model.fit(self.features(X_train), y_train)\n",
        "    print(roc_auc_score(y_test, self.model.predict_proba(self.features(X_test))[:, 1]))\n",
        "  \n",
        "  def predict(self, X):\n",
        "    return self.model.predict(X)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNOX8l_zqnXX",
        "outputId": "76976dd2-5663-45ad-d974-c675f8943671"
      },
      "source": [
        "model = Model()\n",
        "model.train_eval(X, y)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV_mean: 0.7213110197676796, CV_std: 0.036754591689793115\n",
            "0.6965943062584263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQmf6s2W-Do"
      },
      "source": [
        "### **Отсчет по фичам**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao8TTcqexzNR"
      },
      "source": [
        "Скор без NLP фич - 0.5644\n",
        "Скор с NLP фичами:\n",
        "\n",
        "  - эмпирически: 0.6965 (если добавить все слова, а не по типу слов - результат хуже на 0.005)\n",
        "\n",
        "[0.67311508 0.54761905 0.58581349 0.63194444 0.62690005] только глаголы и прилагательные\n",
        "\n",
        "[0.67460317 0.54513889 0.57242063 0.62400794 0.61953017] все слова\n",
        "\n",
        "[0.66617063 0.54662698 0.56150794 0.67311508 0.59465684] глаг+прил, но учитываем наречия как прилагательные\n",
        "\n",
        "CV_mean: 0.7213110197676796, CV_std: 0.036754591689793115 - глаг+прил+нареч\n",
        "\n",
        "  "
      ]
    }
  ]
}