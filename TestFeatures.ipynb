{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestFeatures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3_4FxfJIzHp"
      },
      "source": [
        "### **Импорт библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DDIGZI6IRLv",
        "outputId": "958df424-9f3f-47ca-dfba-e53bbdd5f8d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g1759rCIxzC",
        "outputId": "eb194ba1-8157-4c28-9dcb-ab2d3f9fe16d"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install tqdm\n",
        "!pip install pymorphy2[fast]\n",
        "!pip install fasttext"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.26.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: DAWG>=0.8 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.8.0)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.7.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoDyTCGrJOmT",
        "outputId": "bfd6b8c7-1b7e-4162-f0c1-f63eb76ea570"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import catboost as ctb\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, SpectralClustering\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.test.utils import get_tmpfile\n",
        "import fasttext\n",
        "from gensim.models import FastText, KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn9Yyc2cJ_EH"
      },
      "source": [
        "### **Считываем и смотрим на данные**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3wswvEKKtB"
      },
      "source": [
        "labled_train_data = pd.read_csv('/content/drive/MyDrive/labled_train_data.csv', comment='#', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "labled_train_comments = pd.read_csv('/content/drive/MyDrive/labled_train_comments.csv', comment='#', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "labled_train_speed = pd.read_csv('/content/drive/MyDrive/labled_train_tracks_speed.csv', comment='#', sep=',')\n",
        "labled_train_tracks = pd.read_csv('/content/drive/MyDrive/labled_train_tracks.csv', comment='#', sep='\\t').drop('Unnamed: 0', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "pH7_kpX9NRuU",
        "outputId": "8c104e18-f9a0-437c-98e0-a91021f03f03"
      },
      "source": [
        "labled_train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>driver_id</th>\n",
              "      <th>client_id</th>\n",
              "      <th>dttm</th>\n",
              "      <th>date</th>\n",
              "      <th>arrived_distance</th>\n",
              "      <th>arrived_duration</th>\n",
              "      <th>distance</th>\n",
              "      <th>duration</th>\n",
              "      <th>from_latitude</th>\n",
              "      <th>from_longitude</th>\n",
              "      <th>to_latitude</th>\n",
              "      <th>to_longitude</th>\n",
              "      <th>mark</th>\n",
              "      <th>client_rate_ride</th>\n",
              "      <th>client_rides_cnt</th>\n",
              "      <th>driver_rides_cnt</th>\n",
              "      <th>comment</th>\n",
              "      <th>is_aggressive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a0f322ade1a05e5c4cec4344efbce8b</td>\n",
              "      <td>f7c2b293ef94420f5e51abae6889b83b</td>\n",
              "      <td>3156d05c6458a8228bed59f02075a61e</td>\n",
              "      <td>2021-01-22 21:53:00</td>\n",
              "      <td>2021-01-22</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>20.5</td>\n",
              "      <td>55.795900</td>\n",
              "      <td>37.560300</td>\n",
              "      <td>55.716502</td>\n",
              "      <td>37.524627</td>\n",
              "      <td>Kia K5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>934ecbe5845426fd3f8ef7938cce2a11</td>\n",
              "      <td>01d029c42c99581080a60679fca06ff9</td>\n",
              "      <td>3156d05c6458a8228bed59f02075a61e</td>\n",
              "      <td>2021-01-24 14:09:00</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>570.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>55.716502</td>\n",
              "      <td>37.524627</td>\n",
              "      <td>55.808253</td>\n",
              "      <td>37.638847</td>\n",
              "      <td>Volkswagen Polo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>Да</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5348cb339b63eaea3b2cb57a064ce550</td>\n",
              "      <td>3c88deb7df7a73a24ebc229db9783405</td>\n",
              "      <td>3156d05c6458a8228bed59f02075a61e</td>\n",
              "      <td>2021-01-26 21:02:00</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>10.9</td>\n",
              "      <td>55.716637</td>\n",
              "      <td>37.524223</td>\n",
              "      <td>55.741958</td>\n",
              "      <td>37.568172</td>\n",
              "      <td>MercedesBenz EClass</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>309ef91c3b51e27d097642169576f67b</td>\n",
              "      <td>f35a8ff85f2095755f16bba91035fbdc</td>\n",
              "      <td>3156d05c6458a8228bed59f02075a61e</td>\n",
              "      <td>2021-01-27 17:24:00</td>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>10.7</td>\n",
              "      <td>55.689076</td>\n",
              "      <td>37.491089</td>\n",
              "      <td>55.716502</td>\n",
              "      <td>37.524627</td>\n",
              "      <td>Kia Optima</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3506e04e45d39c6e3033637389da1041</td>\n",
              "      <td>0a227ac8d702170c03acf36d55e60d0d</td>\n",
              "      <td>3156d05c6458a8228bed59f02075a61e</td>\n",
              "      <td>2021-01-29 15:31:00</td>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>55.655489</td>\n",
              "      <td>37.616629</td>\n",
              "      <td>55.716502</td>\n",
              "      <td>37.524627</td>\n",
              "      <td>Kia Rio</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           order_id  ... is_aggressive\n",
              "0  6a0f322ade1a05e5c4cec4344efbce8b  ...             0\n",
              "1  934ecbe5845426fd3f8ef7938cce2a11  ...             0\n",
              "2  5348cb339b63eaea3b2cb57a064ce550  ...             0\n",
              "3  309ef91c3b51e27d097642169576f67b  ...             0\n",
              "4  3506e04e45d39c6e3033637389da1041  ...             0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VOyZOgIrNToa",
        "outputId": "440b6bf6-6ed7-4548-dd4d-29a6df91debe"
      },
      "source": [
        "labled_train_comments.loc[labled_train_comments['driver_id']== '469bbb0b9b7883f9df5924326d868d50'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>driver_id</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>469bbb0b9b7883f9df5924326d868d50</td>\n",
              "      <td>Суперски водитель...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4519</th>\n",
              "      <td>469bbb0b9b7883f9df5924326d868d50</td>\n",
              "      <td>Отличный водитель</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9941</th>\n",
              "      <td>469bbb0b9b7883f9df5924326d868d50</td>\n",
              "      <td>водитель начал поездку не выключив платное ожи...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14627</th>\n",
              "      <td>469bbb0b9b7883f9df5924326d868d50</td>\n",
              "      <td>спасибо за утренний позитивный настрой</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17834</th>\n",
              "      <td>469bbb0b9b7883f9df5924326d868d50</td>\n",
              "      <td>я отменила поездку а с меня списались деньги я...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              driver_id                                            comment\n",
              "0      469bbb0b9b7883f9df5924326d868d50                              Суперски водитель... \n",
              "4519   469bbb0b9b7883f9df5924326d868d50                                 Отличный водитель \n",
              "9941   469bbb0b9b7883f9df5924326d868d50  водитель начал поездку не выключив платное ожи...\n",
              "14627  469bbb0b9b7883f9df5924326d868d50             спасибо за утренний позитивный настрой\n",
              "17834  469bbb0b9b7883f9df5924326d868d50  я отменила поездку а с меня списались деньги я..."
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iIKgKUsLNXAH",
        "outputId": "7cf0b978-0b72-4dd5-be11-c7885846ca4c"
      },
      "source": [
        "labled_train_tracks.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>driver_id</th>\n",
              "      <th>dt</th>\n",
              "      <th>lat_</th>\n",
              "      <th>lon_</th>\n",
              "      <th>order_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5947356660903834a6bc52215fe9ffb2</td>\n",
              "      <td>2021-04-06 21:20:16</td>\n",
              "      <td>55.697662</td>\n",
              "      <td>37.562592</td>\n",
              "      <td>e0437da04323f57500e08d6ce7e8372f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5947356660903834a6bc52215fe9ffb2</td>\n",
              "      <td>2021-04-06 21:23:19</td>\n",
              "      <td>55.706867</td>\n",
              "      <td>37.585470</td>\n",
              "      <td>e0437da04323f57500e08d6ce7e8372f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5947356660903834a6bc52215fe9ffb2</td>\n",
              "      <td>2021-04-06 21:16:52</td>\n",
              "      <td>55.687419</td>\n",
              "      <td>37.544892</td>\n",
              "      <td>e0437da04323f57500e08d6ce7e8372f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5947356660903834a6bc52215fe9ffb2</td>\n",
              "      <td>2021-04-06 21:12:06</td>\n",
              "      <td>55.675340</td>\n",
              "      <td>37.540472</td>\n",
              "      <td>e0437da04323f57500e08d6ce7e8372f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5947356660903834a6bc52215fe9ffb2</td>\n",
              "      <td>2021-04-06 21:10:03</td>\n",
              "      <td>55.672449</td>\n",
              "      <td>37.543454</td>\n",
              "      <td>e0437da04323f57500e08d6ce7e8372f</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          driver_id  ...                          order_id\n",
              "0  5947356660903834a6bc52215fe9ffb2  ...  e0437da04323f57500e08d6ce7e8372f\n",
              "1  5947356660903834a6bc52215fe9ffb2  ...  e0437da04323f57500e08d6ce7e8372f\n",
              "2  5947356660903834a6bc52215fe9ffb2  ...  e0437da04323f57500e08d6ce7e8372f\n",
              "3  5947356660903834a6bc52215fe9ffb2  ...  e0437da04323f57500e08d6ce7e8372f\n",
              "4  5947356660903834a6bc52215fe9ffb2  ...  e0437da04323f57500e08d6ce7e8372f\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "x6fYXGn1M9NJ",
        "outputId": "731a0b28-0b47-4939-a9e1-2d1123cc5077"
      },
      "source": [
        "labled_speed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>driver_id</th>\n",
              "      <th>dt</th>\n",
              "      <th>lat_</th>\n",
              "      <th>lon_</th>\n",
              "      <th>order_id</th>\n",
              "      <th>speed</th>\n",
              "      <th>is_aggressive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b76545fa3cc14acd6a69ac13c1edac33</td>\n",
              "      <td>2021-02-09 21:43:41</td>\n",
              "      <td>55.792710</td>\n",
              "      <td>37.545409</td>\n",
              "      <td>001662da857b5a39bb402aacf3145f86</td>\n",
              "      <td>29.051632</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b76545fa3cc14acd6a69ac13c1edac33</td>\n",
              "      <td>2021-02-09 21:44:40</td>\n",
              "      <td>55.792013</td>\n",
              "      <td>37.544481</td>\n",
              "      <td>001662da857b5a39bb402aacf3145f86</td>\n",
              "      <td>5.906441</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b76545fa3cc14acd6a69ac13c1edac33</td>\n",
              "      <td>2021-02-09 21:45:00</td>\n",
              "      <td>55.791365</td>\n",
              "      <td>37.543695</td>\n",
              "      <td>001662da857b5a39bb402aacf3145f86</td>\n",
              "      <td>15.696000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b76545fa3cc14acd6a69ac13c1edac33</td>\n",
              "      <td>2021-02-09 21:45:20</td>\n",
              "      <td>55.791267</td>\n",
              "      <td>37.543512</td>\n",
              "      <td>001662da857b5a39bb402aacf3145f86</td>\n",
              "      <td>2.862000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b76545fa3cc14acd6a69ac13c1edac33</td>\n",
              "      <td>2021-02-09 21:45:37</td>\n",
              "      <td>55.791175</td>\n",
              "      <td>37.543634</td>\n",
              "      <td>001662da857b5a39bb402aacf3145f86</td>\n",
              "      <td>2.710588</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          driver_id  ... is_aggressive\n",
              "0  b76545fa3cc14acd6a69ac13c1edac33  ...           0.0\n",
              "1  b76545fa3cc14acd6a69ac13c1edac33  ...           0.0\n",
              "2  b76545fa3cc14acd6a69ac13c1edac33  ...           0.0\n",
              "3  b76545fa3cc14acd6a69ac13c1edac33  ...           0.0\n",
              "4  b76545fa3cc14acd6a69ac13c1edac33  ...           0.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujZ8p_kuW4Co"
      },
      "source": [
        "### **Модель**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k6gy6dYqcdS"
      },
      "source": [
        "X, y = labled_train_data[labled_train_data.columns[:-1]], labled_train_data['is_aggressive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr1pH17dFdtt"
      },
      "source": [
        "def doc_to2_vec_clustering(X, y):\n",
        "  # stop_words = set(stopwords.words('russian')) # стоп-слова из nltk\n",
        "  # stop_words.add('')\n",
        "  # stop_words.add(' ')\n",
        "  # stop_words.add('\\t')\n",
        "  # dataset = X.join(y).copy()\n",
        "  # dataset = dataset.loc[dataset['is_aggressive'] == 1]\n",
        "  # data = []\n",
        "  # tag_n = 0\n",
        "  # for row in dataset.itertuples(): # перебираем все строки в датасете\n",
        "  #     if getattr(row, 'comment'):\n",
        "  #       comment = getattr(row, 'comment')\n",
        "  #       comment = [lemmatize_and_word_class(re.sub(r'\\W', '', word.lower()))[0] for word in comment.split(' ') if lemmatize_and_word_class(re.sub(r'\\W', '', word.lower()))[0] not in stop_words and lemmatize_and_word_class(re.sub(r'\\W', '', word.lower()))[0].isalpha()]\n",
        "  #       data.append(TaggedDocument(comment, [tag_n]))\n",
        "  #       tag_n += 1\n",
        "  # model = Doc2Vec(data, min_count=1, size=10, window=4, workers=-1, seed=42, epohs=20)\n",
        "  # print('MODEL D2V TRAINED')\n",
        "  # vectors = []\n",
        "  # for row in dataset.itertuples(): # перебираем все строки в датасете\n",
        "  #     if getattr(row, 'comment'):\n",
        "  #       comment = getattr(row, 'comment')\n",
        "  #       comment = [lemmatize_and_word_class(re.sub(r'\\W', '', word.lower()))[0] for word in comment.split(\" \") if lemmatize_and_word_class(re.sub(r'\\W', '', word.lower()))[0] not in stop_words and lemmatize_and_word_class(re.sub(r'\\W', '', word.lower()))[0].isalpha()]\n",
        "  #       print(comment)\n",
        "  #       vectors.append(model.infer_vector(comment))\n",
        "  # return vectors, model\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jczelf_GGrW"
      },
      "source": [
        "vectors, model = doc_to_vec_clustering(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJplif3u8QAY",
        "outputId": "90bbb515-952a-4b48-b3d8-7ee19c38b6b0"
      },
      "source": [
        "word='a1_2+!'\n",
        "word = re.sub(r'[\\d\\W]', '', word).lower().strip()\n",
        "print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBAht4EnMXb4"
      },
      "source": [
        "kmeans = KMeans(n_clusters=4, random_state=42).fit(vectors)\n",
        "docvec = kmeans.cluster_centers_[2]  # assuming such a doc-tag exists\n",
        "print(docvec)\n",
        "similar_words = model.most_similar(positive=[docvec])\n",
        "print(similar_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wZyoWUU_IA"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self):\n",
        "    self.model = None\n",
        "    self.text_vectorizer = None\n",
        "    self.clustering_model = None\n",
        "\n",
        "    self.aggressive_words = {'verb': set(), 'adj': set(), 'all_words': set(), 'noun': set()}\n",
        "    self.morph_analyzer = MorphAnalyzer()\n",
        "\n",
        "    self.stop_words = set(stopwords.words('russian')) # стоп-слова из nltk\n",
        "    self.stop_words.add('')\n",
        "    self.stop_words.add(' ')\n",
        "    self.stop_words.add('\\t')\n",
        "\n",
        "  # возвращает нормальную форму слова(при normal_form=True, иначе просто слово) и его тэг(характеристики слова)\n",
        "  def word_preprocess(self, word, word_normal_form=False):\n",
        "      word = re.sub(r'[\\d\\W]', '', word).lower().strip() # убирает пробелы, цифры и знаки препинания\n",
        "      word = word.replace('_', '')\n",
        "      w = self.morph_analyzer.parse(word)[0]\n",
        "      if word_normal_form:\n",
        "        return w.normal_form, w.tag\n",
        "      return word, w.tag\n",
        "\n",
        "  # тренировка кластеризатора текстов\n",
        "  def cluster_model_train(self, vectors):\n",
        "    self.clustering_model = KMeans(n_clusters=2, random_state=42, n_init=20)\n",
        "    self.clustering_model.fit(vectors)\n",
        "\n",
        "  # получаем косинусное расстояние для вектора коммента и центров кластеров\n",
        "  def cluster_features(self, text):\n",
        "    similarity = []\n",
        "    clusters = self.clustering_model.cluster_centers_\n",
        "    text = [self.word_preprocess(word, word_normal_form=True)[0] for word in text.split(\" \") if self.word_preprocess(word, word_normal_form=True)[0] not in self.stop_words]\n",
        "    text = [word for word in text if word != '']\n",
        "    if len(text) == 0:\n",
        "      for i in range(len(clusters)):\n",
        "        similarity.append([0,0,0])\n",
        "      return similarity\n",
        "    vector = self.text_vectorizer.infer_vector(text)\n",
        "    similarity = []\n",
        "    for i in range(len(clusters)):\n",
        "      similarity.append([euclidean(vector, clusters[i]), self.clustering_model.predict([vector])[0]])\n",
        "    return similarity\n",
        "\n",
        "  def train_doc2vec_model(self, X, y):\n",
        "    print('training vectorizer model...')\n",
        "    dataset = X.join(y).copy()\n",
        "    # dataset = dataset.loc[dataset['is_aggressive'] == 1]\n",
        "    data = []\n",
        "    tag_n = 0\n",
        "    for row in dataset.itertuples(): # перебираем все строки в датасете\n",
        "        if getattr(row, 'comment'):\n",
        "          comment = getattr(row, 'comment')\n",
        "          comment = [self.word_preprocess(word, word_normal_form=True)[0] for word in comment.split(\" \") if self.word_preprocess(word, word_normal_form=True)[0] not in self.stop_words]\n",
        "          comment = [word for word in comment if word != '']\n",
        "          if len(comment) > 0:\n",
        "            data.append(TaggedDocument(comment, [tag_n]))\n",
        "            tag_n += 1\n",
        "    self.text_vectorizer = Doc2Vec(data, min_count=1, size=30, window=4, workers=-1, seed=42, epohs=15)\n",
        "    print('TEXT WECTORIZER TRAINED')\n",
        "\n",
        "    print('training clustering model...')\n",
        "    vectors = []\n",
        "    for row in dataset.itertuples(): # перебираем все строки в датасете\n",
        "      if getattr(row, 'comment'):\n",
        "        comment = getattr(row, 'comment')\n",
        "        comment = [self.word_preprocess(word, word_normal_form=True)[0] for word in comment.split(\" \") if self.word_preprocess(word, word_normal_form=True)[0] not in self.stop_words]\n",
        "        comment = [word for word in comment if word != '']\n",
        "        if len(comment) > 0:\n",
        "          vectors.append(self.text_vectorizer.infer_vector(comment))\n",
        "    self.cluster_model_train(vectors)\n",
        "    print('CLUSTERING COMPLETED')\n",
        "\n",
        "  # средний рейтинг по комментариям для каждого водителя  (плохо работает, хз че с ними делать), не юзать пока\n",
        "  def mean_comments_aggressive_rate(self, comm_dataset, X):\n",
        "    mean_comments_aggressive_rate = []\n",
        "    driver_ids = X['driver_id']\n",
        "    for driver_id in driver_ids:\n",
        "      driver_comments_rate = []\n",
        "      driver_comments = comm_dataset.loc[comm_dataset['driver_id'] == driver_id]\n",
        "      for comment in driver_comments:\n",
        "        driver_comments_rate.append(self.get_cosine_sim_to_clusters(comment)[2])\n",
        "      mean_comments_aggressive_rate.append(np.mean(driver_comments_rate))\n",
        "    return mean_comments_aggressive_rate\n",
        "\n",
        "  # добавляет слова в словарь агрессивных слов\n",
        "  def fill_agressive_vocab(self, X, y):\n",
        "    dataset = X.join(y).copy()\n",
        "    for row in dataset.itertuples(): # перебираем все строки в датасете\n",
        "      if getattr(row, 'is_aggressive') == 1 and getattr(row, 'comment'):\n",
        "        words = [self.word_preprocess(word, word_normal_form=True) for word in getattr(row, 'comment').split(' ')]\n",
        "        for word in words:\n",
        "          if word[0] not in self.stop_words:\n",
        "            if 'VERB' in word[1]:\n",
        "              self.aggressive_words['verb'].add(word[0])\n",
        "            elif 'ADJF' in word[1] or 'ADJS' in word[1]:\n",
        "              self.aggressive_words['adj'].add(word[0])\n",
        "            elif 'NOUN' in word[1]:\n",
        "              self.aggressive_words['noun'].add(word[0])\n",
        "\n",
        "\n",
        "  # делаем NLP фичи на основе сгенерированного словаря\n",
        "  def NLP_feature_extract(self, X, y=None):\n",
        "    agg_verbs_rate = [] # глаголы\n",
        "    agg_adjs_rate = [] # прилагательные\n",
        "    agg_nouns_rate = [] # существительные\n",
        "    for row in X.itertuples(): # перебираем все строки в датасете\n",
        "      if getattr(row, 'comment'):\n",
        "        words = [self.word_preprocess(word, word_normal_form=True) for word in getattr(row, 'comment').split(' ')]\n",
        "        words_verb = [word[0] for word in words if 'VERB' in word[1] and word[0] not in self.stop_words]\n",
        "        words_adj = [word[0] for word in words if ('ADJF' in word[1] or 'ADJS' in word[1]) and word[0] not in self.stop_words]\n",
        "        words_noun = [word[0] for word in words if 'NOUN' in word[1] and word[0] not in self.stop_words]\n",
        "\n",
        "        if len(words_verb) > 0:\n",
        "          agg_verbs_rate.append(len(set(words_verb) & self.aggressive_words['verb']) / len(words_verb))\n",
        "        else:\n",
        "          agg_verbs_rate.append(0)\n",
        "\n",
        "        if len(words_adj) > 0:\n",
        "          agg_adjs_rate.append(len(set(words_adj) & self.aggressive_words['adj']) / len(words_adj))\n",
        "        else:\n",
        "          agg_adjs_rate.append(0)\n",
        "\n",
        "        if len(words_noun) > 0:\n",
        "          agg_nouns_rate.append(len(set(words_noun) & self.aggressive_words['noun']) / len(words_noun))\n",
        "        else:\n",
        "          agg_nouns_rate.append(0)\n",
        "\n",
        "    return agg_verbs_rate, agg_adjs_rate, agg_nouns_rate\n",
        "\n",
        "  # отбор фичей\n",
        "  def features(self, X, comm_dataset=None):\n",
        "    data = X.copy()\n",
        "    agg_verbs_rate, agg_adjs_rate, agg_nouns_rate = self.NLP_feature_extract(data)\n",
        "\n",
        "    data['agg_verbs_rate'] = agg_verbs_rate\n",
        "    data['agg_adjs_rate'] = agg_adjs_rate\n",
        "    data['agg_nouns_rate'] = agg_nouns_rate\n",
        "\n",
        "    feature_list = ['agg_verbs_rate', 'agg_adjs_rate', 'agg_nouns_rate']\n",
        "\n",
        "    if comm_dataset is not None:\n",
        "      data['mean_comments_aggressive_rate'] = self.mean_comments_aggressive_rate(comm_dataset, X)\n",
        "      feature_list.append('mean_comments_aggressive_rate')\n",
        "\n",
        "\n",
        "    similarities = []\n",
        "    for row in data.itertuples(): # перебираем все строки в датасете\n",
        "      if getattr(row, 'comment'):\n",
        "        comment = getattr(row, 'comment')\n",
        "        similarities.append(self.cluster_features(comment))\n",
        "\n",
        "    for cluster in range(len(self.clustering_model.cluster_centers_)):\n",
        "      data[f\"euclidean_cluster_{cluster + 1}\"] = [similarities[i][cluster][0] for i in range(len(similarities))]\n",
        "      feature_list.append(f\"euclidean_cluster_{cluster + 1}\")\n",
        "    data['cluster'] = [similarities[i][0][1] for i in range(len(similarities))]\n",
        "    feature_list.append('cluster')\n",
        "\n",
        "    # data['is_comment'] = [1 if getattr(row, 'comment') else 0 for row in data.itertuples()]\n",
        "    # feature_list.append('is_comment')\n",
        "\n",
        "    # заполним NaN средними значениями\n",
        "    for feature in feature_list:\n",
        "      data = data.fillna({feature: data[feature].mean()})\n",
        "    return data[feature_list]\n",
        "\n",
        "  # кросс-валидация и предикт на тесте\n",
        "  def train_eval(self, X, y, comm_dataset=None):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    self.fill_agressive_vocab(X_train, y_train)\n",
        "    self.train_doc2vec_model(X_train, y_train)\n",
        "\n",
        "    # self.model = ctb.CatBoostClassifier(random_state=42, iterations=100) # пробовал catboost для интереса\n",
        "    self.model = LogisticRegression(random_state=42)\n",
        "\n",
        "    cv_score = cross_val_score(self.model, self.features(X_train, comm_dataset), y_train, cv=5, scoring='roc_auc')\n",
        "    \n",
        "    self.model.fit(self.features(X_train, comm_dataset), y_train)\n",
        "\n",
        "    print('Test Roc-Auc score:', roc_auc_score(y_test, self.model.predict_proba(self.features(X_test, comm_dataset))[:, 1]))\n",
        "    print('Train Roc-Auc score:', roc_auc_score(y_train, self.model.predict_proba(self.features(X_train, comm_dataset))[:, 1]))\n",
        "    print(f\"CV_mean roc_auc: {np.mean(cv_score)}, CV_folds_score: {cv_score}\")\n",
        "  \n",
        "  def predict(self, X):\n",
        "    return self.model.predict(X)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNOX8l_zqnXX",
        "outputId": "bf9e9ded-f3fa-444d-fc1f-192913e0e9c1"
      },
      "source": [
        "model = Model()\n",
        "model.train_eval(X, y)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training vectorizer model...\n",
            "TEXT WECTORIZER TRAINED\n",
            "training clustering model...\n",
            "CLUSTERING COMPLETED\n",
            "Test Roc-Auc score: 0.6668262373239023\n",
            "Train Roc-Auc score: 0.6838763867242741\n",
            "CV_mean roc_auc: 0.6819522032387957, CV_folds_score: [0.62861001 0.74803329 0.66013863 0.70424985 0.66872923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQmf6s2W-Do"
      },
      "source": [
        "### **Отсчет по фичам**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao8TTcqexzNR"
      },
      "source": [
        "Скор без NLP фич - 0.5644\n",
        "Скор с NLP фичами:\n",
        "\n",
        "  - эмпирически: 0.6965 (если добавить все слова, а не по типу слов - результат хуже на 0.005) CV_mean: 0.7213110197676796, CV_std: 0.036754591689793115 - глаг+прил+сущ (но словарь сформирован для данных, на которых и идет предсказание, поэтому мб и такой скор)\n",
        "\n",
        "  - кластеризация и семантическая модель (doc2vec): 0.640-651 (фичи тип кластера, евклидово расстояние до каждого кластера) CV_mean roc_auc: 0.6625926120596789, CV_folds_score: [0.63023583 0.71938044 0.62881106 0.68139226 0.65314347] косинусное расстояние хоть обычно и юзают для текстов, но тут ухудшило результат(странно)\n",
        "  - эмпирические + кластеризация 0.668 CV_mean roc_auc: 0.6819522032387957, CV_folds_score: [0.62861001 0.74803329 0.66013863 0.70424985 0.66872923]\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRTmviXS5z2b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}