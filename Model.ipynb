{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tJA_bsAaORxI",
        "_fZL4rRiFCio",
        "GTkhnZoHx5JI",
        "UqEQmfo0x5JK",
        "oW92gZ9-x5JL"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcH7T4cJsOzL"
      },
      "source": [
        "# Install environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT4V-uZiJFE-",
        "outputId": "34eaccf9-5065-4dd4-b33c-bf6643ce6807"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr1WxRStyocP",
        "outputId": "aa221e8f-2d4b-4be8-a04c-8e9f58b5cc33"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install sktime\n",
        "!pip install tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-0.26.1-cp37-none-manylinux1_x86_64.whl (67.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 67.4 MB 65 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.26.1\n",
            "Collecting sktime\n",
            "  Downloading sktime-0.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.37.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.51.2)\n",
            "Collecting scikit-learn>=0.24.0\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 62.6 MB/s \n",
            "\u001b[?25hCollecting statsmodels>=0.12.1\n",
            "  Downloading statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (57.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->sktime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.1)\n",
            "Installing collected packages: threadpoolctl, statsmodels, scikit-learn, sktime\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.2 sktime-0.7.0 statsmodels-0.12.2 threadpoolctl-2.2.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1qmmvEyx5I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89907625-afbc-4557-a829-20f130264e91"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from sktime.transformations.panel.rocket import MiniRocket\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsBW5f7rFx0g"
      },
      "source": [
        "RANDOM_STATE = 42"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZNrSHdSORxG"
      },
      "source": [
        "# Speed tracks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJA_bsAaORxI"
      },
      "source": [
        "## Dowload and add <code>aggressive</code> column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWEqnccpORxI"
      },
      "source": [
        "speed_tracks = pd.read_csv(\"/content/drive/MyDrive/aiijc_transport_simpleteam/data/labled_train_tracks_speed.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN7wNwg7ORxJ"
      },
      "source": [
        "speed_tracks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZp3apkVORxK"
      },
      "source": [
        "speed_tracks.speed.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htiuMRStORxK"
      },
      "source": [
        "speed_tracks.groupby('order_id').speed.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WhvnYoORxL"
      },
      "source": [
        "(speed_tracks.speed == 0).sum() / speed_tracks.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gky37KzGORxM"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "speed_tracks['is_aggressive'] = np.zeros(speed_tracks.shape[0])\n",
        "\n",
        "for obj in tqdm(train_labeled.values):\n",
        "    speed_tracks[\"is_aggressive\"].loc[(speed_tracks.order_id == obj[0])] = obj[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtPf-VoEORxM"
      },
      "source": [
        "speed_tracks.to_csv(\"labled_train_tracks_speed.csv\")\n",
        "!cp labled_train_tracks_speed.csv /content/drive/MyDrive/aiijc_transport_simpleteam/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fZL4rRiFCio"
      },
      "source": [
        "## Tracks model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9k0XyKpFrYv"
      },
      "source": [
        "tracks_labled = pd.read_csv(\"/content/drive/MyDrive/aiijc_transport_simpleteam/data/labled_train_tracks_speed.csv\", index_col=0, sep=',', comment='#')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpUnxQZUFCHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "99d19c36-acf0-468c-fda9-c5af49854b3b"
      },
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "# @lru_cache(maxsize=None)\n",
        "def split(arr, chunk_size = 15):\n",
        "    result = []\n",
        "    # get right length of arr so that it equally splits into chunks\n",
        "    length = len(arr)\n",
        "    split_length = length - (length%chunk_size)\n",
        "\n",
        "    for i in range(split_length)[chunk_size::chunk_size]:\n",
        "        result.append(arr[i-chunk_size:i])\n",
        "\n",
        "    return np.array(result)\n",
        "\n",
        "train_labels = []\n",
        "X_train = []\n",
        "\n",
        "for order in tracks_labled['order_id'].unique():\n",
        "    order_df = tracks_labled[tracks_labled['order_id']==order]\n",
        "    order_df.loc[0,'speed']=0\n",
        "    \n",
        "    chunk_size = 15\n",
        "    if order_df.shape[0]<chunk_size:\n",
        "        continue\n",
        "\n",
        "    splitted_arrs = split(order_df.values, chunk_size)\n",
        "    for arr in splitted_arrs:\n",
        "        is_aggressive = arr[0][7]\n",
        "        train_labels.append(is_aggressive)\n",
        "        speed_series = []\n",
        "        for row in arr:  \n",
        "            # append only speed and dt values \n",
        "            speed_series.append(row[6])\n",
        "        X_train.append(pd.Series(speed_series))\n",
        "\n",
        "X_train = pd.DataFrame({'speed':X_train})\n",
        "y_train = np.array(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-9881c2756502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msplitted_arrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitted_arrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mis_aggressive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "byXY-JDRI_M9",
        "outputId": "bb029096-5527-4aa3-b8cc-725064b4d828"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0      0.000000\n",
              "1      5.906441\n",
              "2     15.69600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0      7.432941\n",
              "1      3.720000\n",
              "2      8.04600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0     -0.091778\n",
              "1      3.325714\n",
              "2      2.92800...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0      36.148235\n",
              "1     173.160000\n",
              "2      57.96...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0      0.024739\n",
              "1      4.012500\n",
              "2      9.07826...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15207</th>\n",
              "      <td>0      92.244706\n",
              "1     104.805000\n",
              "2     112.82...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15208</th>\n",
              "      <td>0     103.214118\n",
              "1     107.100000\n",
              "2      96.22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15209</th>\n",
              "      <td>0     104.602500\n",
              "1      89.301176\n",
              "2      97.51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15210</th>\n",
              "      <td>0     -0.035823\n",
              "1      8.820000\n",
              "2      0.86087...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15211</th>\n",
              "      <td>0     69.463636\n",
              "1     50.441538\n",
              "2     50.56941...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15212 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   speed\n",
              "0      0      0.000000\n",
              "1      5.906441\n",
              "2     15.69600...\n",
              "1      0      7.432941\n",
              "1      3.720000\n",
              "2      8.04600...\n",
              "2      0     -0.091778\n",
              "1      3.325714\n",
              "2      2.92800...\n",
              "3      0      36.148235\n",
              "1     173.160000\n",
              "2      57.96...\n",
              "4      0      0.024739\n",
              "1      4.012500\n",
              "2      9.07826...\n",
              "...                                                  ...\n",
              "15207  0      92.244706\n",
              "1     104.805000\n",
              "2     112.82...\n",
              "15208  0     103.214118\n",
              "1     107.100000\n",
              "2      96.22...\n",
              "15209  0     104.602500\n",
              "1      89.301176\n",
              "2      97.51...\n",
              "15210  0     -0.035823\n",
              "1      8.820000\n",
              "2      0.86087...\n",
              "15211  0     69.463636\n",
              "1     50.441538\n",
              "2     50.56941...\n",
              "\n",
              "[15212 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5dbh0AwJA6L",
        "outputId": "fdc229c6-57a0-482e-da5c-a6c9944b7b69"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTTvCCyCGImj",
        "outputId": "ebf1a63d-6af8-415b-8cd8-edf04993300c"
      },
      "source": [
        "from sklearn.model_selection import KFold  \n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sktime.transformations.panel.rocket import MiniRocket\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
        "\n",
        "rocket = MiniRocket()\n",
        "rocket.fit(X_train, y_train)\n",
        "\n",
        "X_train_transform = rocket.transform(X_train,y_train)\n",
        "\n",
        "classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10), normalize = True)\n",
        "classifier.fit(X_train_transform, y_train)\n",
        "\n",
        "X_test_transform = rocket.transform(X_test)\n",
        "classifier.score(X_test_transform, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9368525896414343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk2YRwe9ONnZ"
      },
      "source": [
        "# Model code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bPA-Pcx5JA"
      },
      "source": [
        "class Model:\n",
        "    def __init__(self):        \n",
        "        self.model = None\n",
        "        self.model_tracks = None\n",
        "        self.model_rocket = None\n",
        "\n",
        "        self.counter_words = {}\n",
        "\n",
        "        self.TRACKS_CHUNK_SIZE = 20\n",
        "        self.TRACKS_MULTIPLIER = 1\n",
        "    \n",
        "    def count_words(self, x):\n",
        "        return len(x.split(\" \"))\n",
        "\n",
        "    def check_sentence(self, sentence, words_type):\n",
        "        words_count = 0\n",
        "        for word in sentence.split(\" \"):\n",
        "            word = word.lower().replace(',', '').replace('.', '')\n",
        "\n",
        "            if (word not in list(self.counter_words.keys()) or len(self.counter_words[word]) == 2): continue\n",
        "\n",
        "            if (words_type == self.counter_words[word][2]): \n",
        "                words_count += 1\n",
        "        return words_count\n",
        "        \n",
        "    def NLP_preprocess(self, X ,y):\n",
        "        dataset_joined = X.join(y)\n",
        "        comment_phrases = list(dataset_joined.comment.value_counts().index[: 10])\n",
        "        \n",
        "        dataset_joined['is_comment'] = (~np.isin(dataset_joined.comment, comment_phrases)).astype(int)\n",
        "        \n",
        "        aggressive_comments = dataset_joined[(dataset_joined['is_comment'] == True) & (dataset_joined.is_aggressive == True)].comment.values\n",
        "        normal_comments = dataset_joined[(dataset_joined['is_comment'] == True) & (dataset_joined.is_aggressive == False)].comment.values\n",
        "        \n",
        "        stop_words = ['на', 'по', 'с', 'в', 'что', 'и', 'а']\n",
        "\n",
        "        for sentence in normal_comments:\n",
        "            for word in sentence.split(\" \"):\n",
        "                word = word.lower().replace(',', '').replace('.', '')\n",
        "                if (word in stop_words): continue\n",
        "                if (word in self.counter_words.keys()):\n",
        "                    self.counter_words[word][0] += 1\n",
        "                else: self.counter_words[word] = [1, 0]\n",
        "\n",
        "        for sentence in aggressive_comments:\n",
        "            for word in sentence.split(\" \"):\n",
        "                word = word.lower().replace(',', '').replace('.', '')\n",
        "                if (word in stop_words): continue\n",
        "                if (word in self.counter_words.keys()):\n",
        "                    self.counter_words[word][1] += 1\n",
        "                else: self.counter_words[word] = [0, 1]\n",
        "        \n",
        "        \n",
        "        count_all_words = np.array(list(map(lambda x: np.array(x), np.array(list(self.counter_words.items())).T[1]))).T\n",
        "        \n",
        "        count_normal_words = count_all_words[0].sum()\n",
        "        count_aggressive_words = count_all_words[1].sum()\n",
        "\n",
        "        for word_pair in list(self.counter_words.items()):\n",
        "            if (word_pair[1][1] == 0 and word_pair[1][0] > 0):\n",
        "                self.counter_words[word_pair[0]].append(\"normal\")\n",
        "                continue\n",
        "\n",
        "            if (word_pair[1][0] == 0 and word_pair[1][1] > 0):\n",
        "                self.counter_words[word_pair[0]].append(\"aggressive\")\n",
        "                continue\n",
        "\n",
        "            ratio_aggressive = word_pair[1][1] / count_aggressive_words\n",
        "            ratio_normal = word_pair[1][0] / count_normal_words\n",
        "\n",
        "            if (ratio_aggressive / ratio_normal >= 3):\n",
        "                self.counter_words[word_pair[0]].append(\"aggressive\")\n",
        "                continue\n",
        "\n",
        "            if (ratio_normal / ratio_aggressive >= 3):\n",
        "                self.counter_words[word_pair[0]].append(\"normal\")\n",
        "                continue\n",
        "\n",
        "            self.counter_words[word_pair[0]].append(\"neutral\")\n",
        "\n",
        "    def add_features(self, X):\n",
        "        comment_phrases = list(X.comment.value_counts().index[: 5]) + [\"---\"]\n",
        "        \n",
        "        X[\"is_comment\"] = (~np.isin(X.comment, comment_phrases)).astype(int)\n",
        "        X['dttm'] = pd.to_datetime(X.dttm)\n",
        "        X['hour'] = X.dttm.apply(lambda x: x.hour)\n",
        "        X['traff_jam'] = ((X.hour > 6) & (X.hour < 10)) | ((X.hour > 17) & (X.hour < 23))\n",
        "        X['traff_jam'] = X.traff_jam.astype(int)\n",
        "        X['weekday'] = X.dttm.apply(lambda x: x.weekday())\n",
        "        X['holiday'] = (X.weekday >= 5).astype(int)\n",
        "        X[\"count_words\"] = [-1] * X.shape[0]\n",
        "        X.loc[X.is_comment == True, \"count_words\"] = X[X.is_comment == True].comment.apply(lambda x: self.count_words(x))\n",
        "        X[\"speed\"] = X.distance / (X.duration / 60)\n",
        "        X['agg_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"aggressive\"))\n",
        "        X['normal_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"normal\"))\n",
        "        X['distance_thresh'] = ((X.distance > 5) & (X.distance < 20)).astype(int)\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def estimate(self, X, y):\n",
        "        return roc_auc_score(y, self.predict_proba(X, add_feat=False))\n",
        "    \n",
        "    def train_test_split_(self, X, y, test_size, X_ss=None, y_ss=None, random_state=RANDOM_STATE):\n",
        "        if (X_ss is not None):\n",
        "            X_ss_full, y_ss_full = self.label_shuffle(X, y, X_ss, y_ss, random_state = random_state)\n",
        "            \n",
        "            len_train = len(X_ss_full) - round(len(X_ss_full) * test_size)\n",
        "            \n",
        "            x_train = X_ss_full[: len_train]\n",
        "            x_train.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            x_test = X_ss_full.iloc[len_train + 1:]\n",
        "            x_test = x_test[x_test.ss == 0]\n",
        "            x_test.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            y_train = y_ss_full[: len_train]\n",
        "            y_train.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            y_test = y_ss_full.iloc[len_train + 1:]\n",
        "            y_test = y_test[y_test.ss == 0]\n",
        "            y_test.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            return (x_train, x_test, y_train, y_test)\n",
        "        \n",
        "        len_train = len(X) - round(len(X) * test_size)\n",
        "        \n",
        "        X = X.sample(frac=1, random_state=random_state)\n",
        "        y = y.sample(frac=1, random_state=random_state)\n",
        "        \n",
        "        return (X[: len_train], X[len_train :], y[: len_train], y[len_train :])\n",
        "    \n",
        "    def train(self, X_train, X_test, y_train, y_test, categorical_feature, random_state=RANDOM_STATE):\n",
        "        print(f\"Train size: {X_train.shape}\")\n",
        "        print(f\"Test size: {X_test.shape}\")\n",
        "        self.model = CatBoostClassifier(iterations=2000,\n",
        "                           depth=2,\n",
        "                           silent=True,\n",
        "                           loss_function='Logloss',\n",
        "                           class_weights=(1, 2),\n",
        "                           random_state=random_state)\n",
        "\n",
        "        self.model.fit(X_train, y_train, cat_features=categorical_features)\n",
        "        \n",
        "        return self.estimate(X_test, y_test)\n",
        "    \n",
        "    def label_shuffle(self, X, y, X_ss, y_ss, random_state=RANDOM_STATE):\n",
        "        X_ss['ss'] = 1\n",
        "        y_ss = y_ss.to_frame()\n",
        "        y_ss['ss'] = 1\n",
        "\n",
        "        X['ss'] = 0\n",
        "        y['ss'] = 0\n",
        "\n",
        "        X_ss_full = pd.concat([X, X_ss]).sample(frac=1, random_state=random_state)\n",
        "        y_ss_full = pd.concat([y, y_ss]).sample(frac=1, random_state=random_state)\n",
        "        \n",
        "        return (X_ss_full, y_ss_full)\n",
        "    \n",
        "    def train_cross_validation(self, X, y, k, categorical_features, X_ss=None, y_ss=None, random_state=RANDOM_STATE):\n",
        "        chunk_size = len(X) / k\n",
        "        chunks_size = [(i*chunk_size, i*chunk_size + chunk_size) for i in range(k)]\n",
        "        \n",
        "        result_score = []\n",
        "        \n",
        "        print(f\"Part size: {chunk_size}\")\n",
        "        \n",
        "        if (X_ss is not None):\n",
        "            X_ss_full, y_ss_full = self.label_shuffle(X, y, X_ss, y_ss, random_state = random_state)\n",
        "            \n",
        "            for chunkIndex in range(len(chunks_size)):\n",
        "                x_test = X_ss_full[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                y_test = y_ss_full[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                \n",
        "                x_train = X_ss_full.drop(x_test.index, axis = 0)\n",
        "                y_train = y_ss_full.drop(y_test.index, axis = 0)\n",
        "                \n",
        "                x_test = x_test[x_test.ss == 0]\n",
        "                y_test = y_test[y_test.ss == 0]\n",
        "                \n",
        "                x_train.drop('ss', axis = 1, inplace = True)\n",
        "                y_train.drop('ss', axis = 1, inplace = True)\n",
        "                x_test.drop('ss', axis = 1, inplace = True)\n",
        "                y_test.drop('ss', axis = 1, inplace = True)\n",
        "                \n",
        "                score = self.train(x_train, x_test, y_train, y_test, categorical_features)\n",
        "                \n",
        "                print(f\"Chunk {chunkIndex}; Score: {score}\")\n",
        "                \n",
        "                result_score.append((chunks_size[chunkIndex], score))\n",
        "        else:            \n",
        "            for chunkIndex in range(len(chunks_size)):\n",
        "                x_test = X[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                y_test = y[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                \n",
        "                x_train = X.drop(x_test.index, axis = 0)\n",
        "                y_train = y.drop(y_test.index, axis = 0)\n",
        "                \n",
        "                score = self.train(x_train, x_test, y_train, y_test, categorical_features)\n",
        "                \n",
        "                print(f\"Chunk {chunkIndex}; Score: {score}\")\n",
        "                \n",
        "                result_score.append((chunks_size[chunkIndex], score))\n",
        "            \n",
        "        print(f\"Mean score: {sum(list(map(lambda x: x[1], result_score))) / k}\")\n",
        "        \n",
        "        return result_score\n",
        "    \n",
        "    def fit_ss(self, X, y, numeric_features, categorial_features, X_ss, y_ss, cross_validation=False, random_state=RANDOM_STATE):\n",
        "        self.counter_words = {}\n",
        "        \n",
        "        X_ = X\n",
        "        y_ = y\n",
        "        \n",
        "        self.NLP_preprocess(pd.concat([X_, X_ss]), pd.concat([y_, y_ss]))\n",
        "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
        "        \n",
        "        X_ss = self.add_features(X_ss)[numeric_features + categorical_features]\n",
        "        \n",
        "        if (not cross_validation):\n",
        "            X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, X_ss=X_ss, y_ss=y_ss, random_state=random_state)\n",
        "            return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
        "        else:\n",
        "            return self.train_cross_validation(X_, y_, 5, categorical_features, X_ss=X_ss, y_ss=y_ss, random_state=random_state)\n",
        "        \n",
        "        \n",
        "    def fit(self, X, y, numeric_features, categorial_features, cross_validation=False, random_state=RANDOM_STATE):\n",
        "        self.counter_words = {}\n",
        "        \n",
        "        X_ = X\n",
        "        y_ = y\n",
        "        \n",
        "        self.NLP_preprocess(X_, y_)\n",
        "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
        "\n",
        "        if (not cross_validation):\n",
        "            X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, random_state=random_state)\n",
        "            return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
        "        else:\n",
        "            return self.train_cross_validation(X_, y_, 5, categorical_features, random_state=random_state)\n",
        "\n",
        "    def fit_tracks(self, tracks, random_state=RANDOM_STATE):\n",
        "        print(\"Preprocessing tracks data...\")\n",
        "        X, y = self.tracks_preprocess(tracks, self.TRACKS_CHUNK_SIZE, self.TRACKS_MULTIPLIER)\n",
        "\n",
        "        print(\"Training MiniRocket...\")\n",
        "        self.model_rocket = MiniRocket()\n",
        "        self.model_rocket.fit(X, y)\n",
        "\n",
        "        print(\"MiniRocket Transforming...\")\n",
        "        X_train_transform = self.model_rocket.transform(X, y)\n",
        "\n",
        "        print(\"Training logistic regression...\")\n",
        "        self.model_tracks = RidgeClassifierCV(normalize = True)\n",
        "        self.model_tracks.fit(X_train_transform, y)\n",
        "        \n",
        "        print(f\"Score: {self.model_tracks.score(X_train_transform, y)}\")\n",
        "    \n",
        "    def predict_tracks(self, tracks):\n",
        "        print(\"Preprocessing tracks data...\")\n",
        "        X = self.tracks_preprocess(tracks, self.TRACKS_CHUNK_SIZE, self.TRACKS_MULTIPLIER, labled=False)\n",
        "        \n",
        "        print(\"MiniRocket Transforming...\")\n",
        "        X_transform = self.model_rocket.transform(X)\n",
        "\n",
        "        return self.model_tracks.predict(X_transform)\n",
        "\n",
        "    def predict_proba(self, X, add_feat=True):\n",
        "        if (add_feat): X = self.add_features(X)\n",
        "        \n",
        "        X = X[numeric_features + categorical_features]\n",
        "        \n",
        "        return self.model.predict_proba(X).T[1]\n",
        "    \n",
        "    def predict(self, X, add_feat=True):\n",
        "        if (add_feat): X = self.add_features(X)\n",
        "        \n",
        "        X = X[numeric_features + categorical_features]\n",
        "        \n",
        "        return self.model.predict(X)\n",
        "    \n",
        "    def predict_thresh(self, X, thresh_above, thresh_below):\n",
        "        y_unlab_full = self.predict_proba(X)\n",
        "        \n",
        "        y_unlab = pd.Series([-1 for i in range(len(X))])\n",
        "        \n",
        "        print(\"Thresh above: {}\".format(sum(y_unlab_full >= thresh_above) / len(y_unlab_full)))\n",
        "        print(\"Thresh below: {}\".format(sum(y_unlab_full <= thresh_below) / len(y_unlab_full)))\n",
        "        \n",
        "        y_unlab.iloc[np.where(y_unlab_full >= thresh_above)] = 1\n",
        "        y_unlab.iloc[np.where(y_unlab_full <= thresh_below)] = 0\n",
        "        \n",
        "        return y_unlab\n",
        "\n",
        "    # undersampling method deletes some extra non aggressive values\n",
        "    def undersampling(self, X, multiplier):\n",
        "        aggressive_count = sum(X.is_aggressive==1)\n",
        "        non_aggressive_ind = X[X.is_aggressive==0].index\n",
        "\n",
        "        # number of aggressive and non-aggressive labels is the same\n",
        "        random_indices = np.random.choice(non_aggressive_ind, int(aggressive_count*multiplier), replace=False)\n",
        "        return pd.concat([X.loc[random_indices], X[X.is_aggressive==1]])\n",
        "\n",
        "    def split(self, arr, chunk_size = 15):\n",
        "        result = []\n",
        "        #get right length of arr so that it equally splits into chunks\n",
        "        length = len(arr)\n",
        "        split_length = length - (length%chunk_size)\n",
        "                \n",
        "        for i in range(split_length)[chunk_size::chunk_size]:\n",
        "            result.append(arr[i-chunk_size:i])\n",
        "\n",
        "        return np.array(result)\n",
        "\n",
        "    # make df, so that each row has whole order speeds time series\n",
        "    def make_nested(self, tracks, chunk_size, multiplier, labled):\n",
        "        unique_orders = tracks.drop_duplicates('order_id', keep='last')\n",
        "        if labled:\n",
        "            unique_orders = self.undersampling(unique_orders, multiplier)\n",
        "        y_labels = []\n",
        "        X_train = []\n",
        "        for order in tqdm(unique_orders['order_id']):\n",
        "            order_df = tracks[tracks.order_id == order]\n",
        "            order_df.loc[0, 'speed'] = 0\n",
        "\n",
        "            if order_df.shape[0] < chunk_size:\n",
        "                continue\n",
        "\n",
        "            splitted_arrs = self.split(order_df.values, chunk_size)\n",
        "            for arr in splitted_arrs:\n",
        "                if labled:\n",
        "                    is_aggressive = arr[0][6]\n",
        "                    y_labels.append(is_aggressive)\n",
        "                speed_series = []\n",
        "                for row in arr:  \n",
        "                    # append only speed and dt values \n",
        "                    speed_series.append(row[5])\n",
        "                X_train.append(pd.Series(speed_series))\n",
        "        return X_train, y_labels\n",
        "    \n",
        "    def tracks_preprocess(self, tracks, chunk_size, multiplier, labled=True):\n",
        "        X_train, train_labels = self.make_nested(tracks, chunk_size, multiplier, labled)\n",
        "\n",
        "        X_train = pd.DataFrame({'speed': X_train})\n",
        "        if not labled: return X_train\n",
        "        y_train = np.array(train_labels)\n",
        "\n",
        "        return X_train, y_train"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbSXf2PYx5JF"
      },
      "source": [
        "# Train on labled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roi11zG3x5JF"
      },
      "source": [
        "train_labled = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/labled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_labled = pd.read_csv(\"/content/drive/MyDrive/aiijc_transport_simpleteam/data/labled_train_tracks_speed.csv\", index_col=0, sep=',', comment='#')\n",
        "tracks_unlabled = pd.read_csv(\"/content/drive/MyDrive/aiijc_transport_simpleteam/data/unlabled_train_tracks_speed.csv\", index_col=0, sep=',', comment='#')\n",
        "\n",
        "X_ = train_labled.iloc[:, :-1]\n",
        "y_ = train_labled.iloc[:, -1:]\n",
        "\n",
        "X_['client_rate_ride'] = X_['client_rate_ride'].fillna(X_['client_rate_ride'].mean())\n",
        "X_['client_rides_cnt'] = X_['client_rides_cnt'].fillna(X_['client_rides_cnt'].mean())\n",
        "X_['driver_rides_cnt'] = X_['driver_rides_cnt'].fillna(X_['driver_rides_cnt'].mean())"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFkCdcz_CHyN"
      },
      "source": [
        "tracks_labled.drop(['Unnamed: 0.1'], axis=1, inplace=True)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5W_90wZx5JG"
      },
      "source": [
        "numeric_features = ['distance', 'arrived_distance', 'arrived_duration', 'duration', 'driver_rides_cnt', 'client_rides_cnt', 'client_rate_ride', 'count_words']\n",
        "\n",
        "categorical_features = ['mark', 'is_comment', 'hour', 'weekday', 'agg_words', 'normal_words']"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtnR68K3rSZa",
        "outputId": "43e29fb6-9759-4ead-a086-b1138ba631ab"
      },
      "source": [
        "model_supervised = Model()\n",
        "\n",
        "model_supervised.fit_tracks(tracks_labled)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing tracks data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 864/864 [00:21<00:00, 40.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training MiniRocket...\n",
            "MiniRocket Transforming...\n",
            "Training logistic regression...\n",
            "Score: 0.8022388059701493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_nSSTw9twl3",
        "outputId": "e0aaf26e-b69e-4ee7-ed1b-7f4df4f869b7"
      },
      "source": [
        " tracks = model_supervised.predict_tracks(tracks_labled)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing tracks data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9000/9000 [03:43<00:00, 40.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MiniRocket Transforming...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE6njfkVIcAp",
        "outputId": "1d1bf2cc-8da3-4206-cad4-59c5b751226f"
      },
      "source": [
        "tracks.sum()"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6290.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isOUOO2dshLp",
        "outputId": "0c5128a3-f225-4de1-d7cb-ae0288cbadb5"
      },
      "source": [
        "tracks.shape[0]"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if5I7b5Cx5JG",
        "outputId": "b8d1d962-bd8d-4dce-a50d-6125c975ab1f"
      },
      "source": [
        "model_supervised = Model()\n",
        "\n",
        "model_supervised.fit(X_, y_, numeric_features, categorical_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: (7200, 14)\n",
            "Test size: (1800, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8362260536398467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBM0T9fax5JH",
        "outputId": "f8f6b0e7-a6c1-4462-f457-d34708ad6499"
      },
      "source": [
        "model_cv = Model()\n",
        "\n",
        "model_cv.fit(X_, y_, numeric_features, categorical_features, cross_validation = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Part size: 1800.0\n",
            "Train size: (7200, 14)\n",
            "Test size: (1800, 14)\n",
            "Chunk 0; Score: 0.7501325765301662\n",
            "Train size: (7200, 14)\n",
            "Test size: (1800, 14)\n",
            "Chunk 1; Score: 0.7869791274206916\n",
            "Train size: (7200, 14)\n",
            "Test size: (1800, 14)\n",
            "Chunk 2; Score: 0.7333526906697638\n",
            "Train size: (7200, 14)\n",
            "Test size: (1800, 14)\n",
            "Chunk 3; Score: 0.7684012885885325\n",
            "Train size: (7200, 14)\n",
            "Test size: (1800, 14)\n",
            "Chunk 4; Score: 0.7787730470989159\n",
            "Mean score: 0.7635277460616141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0.0, 1800.0), 0.7501325765301662),\n",
              " ((1800.0, 3600.0), 0.7869791274206916),\n",
              " ((3600.0, 5400.0), 0.7333526906697638),\n",
              " ((5400.0, 7200.0), 0.7684012885885325),\n",
              " ((7200.0, 9000.0), 0.7787730470989159)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTweSMJMx5JH"
      },
      "source": [
        "# Semi-supervised train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTkhnZoHx5JI"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faMhkd_2x5JI"
      },
      "source": [
        "X_unlab = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/unlabled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "comments_unlabeled = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/unlabled_train_comments.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_unlabeled = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/unlabled_train_tracks.csv', index_col=0, sep='\\t', comment='#')\n",
        "\n",
        "X_unlab['client_rate_ride'] = X_unlab['client_rate_ride'].fillna(X_unlab['client_rate_ride'].mean())\n",
        "X_unlab['client_rides_cnt'] = X_unlab['client_rides_cnt'].fillna(X_unlab['client_rides_cnt'].mean())\n",
        "X_unlab['driver_rides_cnt'] = X_unlab['driver_rides_cnt'].fillna(X_unlab['driver_rides_cnt'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "murUE39Rx5JJ",
        "outputId": "70f08b78-8dac-4307-c4ad-8ed28793190d"
      },
      "source": [
        "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.64866629360194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9_4PR_xx5JJ",
        "outputId": "b239c8f3-424b-4815-cf7f-f770685f6afa"
      },
      "source": [
        "np.where(X_unlab.comment.isna())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2762,  3239,  3574, ..., 10719, 10720, 10721])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LTfgggjLx5JJ"
      },
      "source": [
        "for nanIndex in np.where(X_unlab.comment.isna())[0]:\n",
        "    obj_comment = comments_unlabeled.loc[nanIndex]\n",
        "    \n",
        "    if (len(obj_comment) != 0):\n",
        "        X_unlab.comment.iloc[nanIndex] = obj_comment.comment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUvW5EXYx5JJ",
        "outputId": "6ce4fadd-d067-4cae-e1f9-25132348ea51"
      },
      "source": [
        "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00018653236336504383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UH_STafx5JK"
      },
      "source": [
        "X_unlab.comment.iloc[np.where(X_unlab.comment.isna())[0]] = \"---\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqEQmfo0x5JK"
      },
      "source": [
        "## Prediction&filling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSEcB99Ex5JK",
        "outputId": "0b278408-1f90-4617-bf0d-b25381fc25ac"
      },
      "source": [
        "y_unlab = model_supervised.predict_thresh(X_unlab, 0.99, 0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thresh above: 0.003357582540570789\n",
            "Thresh below: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_hR7Co0x5JK"
      },
      "source": [
        "y_unlab.name = \"is_aggressive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qKiVFbKx5JK",
        "outputId": "943ed4b0-8e91-40ed-955f-c82bb176e075"
      },
      "source": [
        "y_unlab.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    10686\n",
              " 1       36\n",
              "Name: is_aggressive, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcTdG9nWx5JL"
      },
      "source": [
        "X_unlab_lab = X_unlab.iloc[np.where(y_unlab != -1)]\n",
        "y_unlab_lab = y_unlab.iloc[np.where(y_unlab != -1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz7y4knWx5JL",
        "outputId": "368b8e8c-6e05-4de5-bbc3-f7c8fc6ead77"
      },
      "source": [
        "X_unlab_lab.comment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7        1)Водитель играл в «шашки» на дороге и игрался...\n",
              "202              2 раза списали деньги, верните пожалуйста\n",
              "351      засыпал за рулём,  съезжал с дороги, приходило...\n",
              "551               резкие повороты. водитель резко тормозил\n",
              "568      Водитель смотрит кино на втором телефоне, проп...\n",
              "705      Вел медленно по бордовым дорогам, сказал «пешк...\n",
              "1317     Водитель резко тормозил, обгонял, кричал на др...\n",
              "1378                             Водитель вел себя грубо. \n",
              "1634     Водитель постоянно громко разговаривал на своё...\n",
              "1667     Водитель в возрасте, несколько раз отвечал на ...\n",
              "1707     Водитель 2 раза поругался с другими таксистами...\n",
              "1975     Водитель опасно вел автомобиль. Было ощущение ...\n",
              "2221     Водитель явно засыпал за рулём, постоянно зева...\n",
              "2261      Приехала другая машина вместо указанной в заказе\n",
              "2302                       Водитель неадекватно себя вёл, \n",
              "2346     Проехал на красный свет дважды на перекрестках...\n",
              "2472                      водит опасно и очень неаккуратно\n",
              "2890                           Резкие повороты на скорости\n",
              "2926     Водитель ехал по выделенной полосе со скорость...\n",
              "3113     Водитель был не пристегнут, вульгарно общался ...\n",
              "3605     Опасное вождение, даже укачало. Отличался номе...\n",
              "3640     водительница очень резко тормозит каждый раз, ...\n",
              "3845     приехал не туда,пришлось идти ,прокурен салон ...\n",
              "3902     Водитель не нажал кнопку \"начать поездку\" и с ...\n",
              "4369     Не понимает когда человек говорить не хочет, г...\n",
              "4553     Не доехали до конечной точки. То ли ошибка при...\n",
              "4658     Грязно в машине ,сидения в пятнах ,резко тормо...\n",
              "5819     я первый раз в жизни ездила с таким водителем,...\n",
              "7431     Заехал на заправку не предупредив, хотя мы опа...\n",
              "8506     не смогла перевести деньги. водитель позвоните...\n",
              "8660              Водитель создал аварийную ситуацию !!!! \n",
              "8837                    почему от меня личный деньги снял,\n",
              "9021     Водитель постоянно открывал дверь и харкал; ма...\n",
              "9862     ужасно медленный водитель, ехал 40-50 км в час...\n",
              "10369    водитель хамит, постоянно переписывается в мес...\n",
              "10711    высадил меня прямо посреди большой лужи со сне...\n",
              "Name: comment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kETFZg8x5JL",
        "outputId": "66154712-a8b9-4a42-e0c3-9c77639423f8"
      },
      "source": [
        "X_unlab_lab.is_comment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    36\n",
              "Name: is_comment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW92gZ9-x5JL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKxX4spJx5JM",
        "outputId": "34cde40f-1bff-4222-de55-67c2e9ef09e5"
      },
      "source": [
        "model_semisupervised = Model()\n",
        "\n",
        "model_semisupervised.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: (7229, 14)\n",
            "Test size: (1798, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8488724212067151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QuIHA4Ux5JM",
        "outputId": "ef68e8cb-f1a5-4175-bf3f-e0a62b4c5d6e"
      },
      "source": [
        "model_ss_cv = Model()\n",
        "\n",
        "model_ss_cv.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab, cross_validation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Part size: 1800.0\n",
            "Train size: (7224, 14)\n",
            "Test size: (1791, 14)\n",
            "Chunk 0; Score: 0.7396306537625914\n",
            "Train size: (7228, 14)\n",
            "Test size: (1797, 14)\n",
            "Chunk 1; Score: 0.742049078955933\n",
            "Train size: (7224, 14)\n",
            "Test size: (1794, 14)\n",
            "Chunk 2; Score: 0.7889097744360902\n",
            "Train size: (7225, 14)\n",
            "Test size: (1790, 14)\n",
            "Chunk 3; Score: 0.7370420937809273\n",
            "Train size: (7226, 14)\n",
            "Test size: (1792, 14)\n",
            "Chunk 4; Score: 0.85435199720914\n",
            "Mean score: 0.7723967196289363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0.0, 1800.0), 0.7396306537625914),\n",
              " ((1800.0, 3600.0), 0.742049078955933),\n",
              " ((3600.0, 5400.0), 0.7889097744360902),\n",
              " ((5400.0, 7200.0), 0.7370420937809273),\n",
              " ((7200.0, 9000.0), 0.85435199720914)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7riHsyVAzwLC"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsJBImFvzvoy"
      },
      "source": [
        "X_test = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/labled_test_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_test = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/labled_test_tracks.csv', index_col=0, sep='\\t', comment='#')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JvU1xokzB_th",
        "outputId": "5429df27-0d0e-4566-f0f7-c90710f81954"
      },
      "source": [
        "tracks_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>driver_id</th>\n",
              "      <th>dt</th>\n",
              "      <th>lat_</th>\n",
              "      <th>lon_</th>\n",
              "      <th>order_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d19911199e1a36b0efcfff74d2e48041</td>\n",
              "      <td>2021-04-09 07:52:33</td>\n",
              "      <td>55.744270</td>\n",
              "      <td>37.495416</td>\n",
              "      <td>a81c18d7605310bcfbaf2100a3dfc996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>710c3859a47f8214355bcae973cd1fcc</td>\n",
              "      <td>2021-04-09 23:11:32</td>\n",
              "      <td>55.805541</td>\n",
              "      <td>37.582749</td>\n",
              "      <td>c22a9913e7c3f7f95702bccc9eed16a8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5cd67d0bcf20c02d6700512c56212e4d</td>\n",
              "      <td>2021-04-09 23:51:36</td>\n",
              "      <td>55.738284</td>\n",
              "      <td>37.628273</td>\n",
              "      <td>86656ff0f2433f53b17b55a0f7429285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1a7cc954f3594034a0ac4ce884c0b3cf</td>\n",
              "      <td>2021-04-09 21:13:18</td>\n",
              "      <td>55.690053</td>\n",
              "      <td>37.559565</td>\n",
              "      <td>0eb2d643f9fcf1e6816e17b0a43e6779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6ae93e9f1d5aae8bb0e3ebedaf46f60c</td>\n",
              "      <td>2021-04-09 07:09:55</td>\n",
              "      <td>55.693317</td>\n",
              "      <td>37.940072</td>\n",
              "      <td>615760202d3d45f6192830ddd6924267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76658</th>\n",
              "      <td>9a34ad2bc3f54a400bbccc3e13c4aa66</td>\n",
              "      <td>2021-04-03 20:41:12</td>\n",
              "      <td>55.781854</td>\n",
              "      <td>37.727598</td>\n",
              "      <td>5166692186266da273d09ad1cd448361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76659</th>\n",
              "      <td>5afc8eb8b21abdba1128e8e5570995fe</td>\n",
              "      <td>2021-04-03 16:59:35</td>\n",
              "      <td>55.649680</td>\n",
              "      <td>37.835034</td>\n",
              "      <td>bfdd4d1fd140d5ec2f49b634a661ab23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76660</th>\n",
              "      <td>03f4a73e682696649185aaa89c1e4a0e</td>\n",
              "      <td>2021-04-03 23:46:41</td>\n",
              "      <td>55.782393</td>\n",
              "      <td>37.598270</td>\n",
              "      <td>a3a6e9104be084052f5120c3ec5f2da5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76665</th>\n",
              "      <td>eea9eef46e30e047fac89fb588b42c02</td>\n",
              "      <td>2021-04-03 20:56:52</td>\n",
              "      <td>55.828086</td>\n",
              "      <td>37.530405</td>\n",
              "      <td>ebec12c2768f1f5d8239e2911acfea09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76667</th>\n",
              "      <td>1cd62951096a32c2d03258071dca18f2</td>\n",
              "      <td>2021-04-03 17:07:10</td>\n",
              "      <td>55.768735</td>\n",
              "      <td>37.519290</td>\n",
              "      <td>2cb18f7d728c0322dc67b096972beabc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71432 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              driver_id  ...                          order_id\n",
              "0      d19911199e1a36b0efcfff74d2e48041  ...  a81c18d7605310bcfbaf2100a3dfc996\n",
              "1      710c3859a47f8214355bcae973cd1fcc  ...  c22a9913e7c3f7f95702bccc9eed16a8\n",
              "2      5cd67d0bcf20c02d6700512c56212e4d  ...  86656ff0f2433f53b17b55a0f7429285\n",
              "3      1a7cc954f3594034a0ac4ce884c0b3cf  ...  0eb2d643f9fcf1e6816e17b0a43e6779\n",
              "4      6ae93e9f1d5aae8bb0e3ebedaf46f60c  ...  615760202d3d45f6192830ddd6924267\n",
              "...                                 ...  ...                               ...\n",
              "76658  9a34ad2bc3f54a400bbccc3e13c4aa66  ...  5166692186266da273d09ad1cd448361\n",
              "76659  5afc8eb8b21abdba1128e8e5570995fe  ...  bfdd4d1fd140d5ec2f49b634a661ab23\n",
              "76660  03f4a73e682696649185aaa89c1e4a0e  ...  a3a6e9104be084052f5120c3ec5f2da5\n",
              "76665  eea9eef46e30e047fac89fb588b42c02  ...  ebec12c2768f1f5d8239e2911acfea09\n",
              "76667  1cd62951096a32c2d03258071dca18f2  ...  2cb18f7d728c0322dc67b096972beabc\n",
              "\n",
              "[71432 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876gjCvrCBQw"
      },
      "source": [
        "model_supervised.tracks_model.predict(tracks_labled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MfxIWbMw2aKc",
        "outputId": "83a6551f-56d1-450f-830d-f384b09263b4"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_id</th>\n",
              "      <th>driver_id</th>\n",
              "      <th>client_id</th>\n",
              "      <th>dttm</th>\n",
              "      <th>date</th>\n",
              "      <th>arrived_distance</th>\n",
              "      <th>arrived_duration</th>\n",
              "      <th>distance</th>\n",
              "      <th>duration</th>\n",
              "      <th>from_latitude</th>\n",
              "      <th>from_longitude</th>\n",
              "      <th>to_latitude</th>\n",
              "      <th>to_longitude</th>\n",
              "      <th>mark</th>\n",
              "      <th>client_rate_ride</th>\n",
              "      <th>client_rides_cnt</th>\n",
              "      <th>driver_rides_cnt</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49430c6531d098d3b288d95d7d1e7f4f</td>\n",
              "      <td>21348747875e0b01bc492d32b49c638d</td>\n",
              "      <td>4d4d06feddc5669339b1cd9d7941a116</td>\n",
              "      <td>2021-04-03 14:49:46</td>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>19.4</td>\n",
              "      <td>55.822578</td>\n",
              "      <td>37.596844</td>\n",
              "      <td>55.792253</td>\n",
              "      <td>37.599762</td>\n",
              "      <td>Skoda Octavia</td>\n",
              "      <td>5.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d3fff1a829a5b5ccbccd40c9895ff4b0</td>\n",
              "      <td>398fe459519b5facba93168b71df0625</td>\n",
              "      <td>2a41e0a45a19a892e960d6c4bef5c27b</td>\n",
              "      <td>2021-04-03 15:02:44</td>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>790.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>55.609624</td>\n",
              "      <td>37.719165</td>\n",
              "      <td>55.596660</td>\n",
              "      <td>37.763549</td>\n",
              "      <td>Hyundai Solaris</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f73533b8aab3b1d7b52488d954a46fa0</td>\n",
              "      <td>951410ef679f167e6515ea5e4d5fb92d</td>\n",
              "      <td>9a8017ac4e8b0ce55b0dbd75c2f25445</td>\n",
              "      <td>2021-04-03 15:04:47</td>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.4</td>\n",
              "      <td>55.570245</td>\n",
              "      <td>37.576624</td>\n",
              "      <td>55.524880</td>\n",
              "      <td>37.589531</td>\n",
              "      <td>Volkswagen Polo</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>Все отлично!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43c6c249e4751b9ba0cf68de3e40a053</td>\n",
              "      <td>311ac9352166fb9b2f9153581b03ab5b</td>\n",
              "      <td>2f9a136bb3baa4912748a981033fd272</td>\n",
              "      <td>2021-04-03 15:05:58</td>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>27.0</td>\n",
              "      <td>55.747910</td>\n",
              "      <td>37.691090</td>\n",
              "      <td>55.750109</td>\n",
              "      <td>37.585366</td>\n",
              "      <td>Hyundai Solaris</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>Водитель чихает без маски не прикрывая нос</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b88dccdeaa7c5c1478915d7532082cda</td>\n",
              "      <td>cccd0c6d3ce5a7c553a1f28086beef5a</td>\n",
              "      <td>121a25147dafdb4565cf4eb6db7302f6</td>\n",
              "      <td>2021-04-03 15:10:29</td>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.8</td>\n",
              "      <td>38.2</td>\n",
              "      <td>55.849331</td>\n",
              "      <td>37.494747</td>\n",
              "      <td>55.725583</td>\n",
              "      <td>37.449681</td>\n",
              "      <td>Kia Cerato</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>dde84eeec63c85f1a1dc1f5321c9d424</td>\n",
              "      <td>a6e1800b310773694593ce2f810de76d</td>\n",
              "      <td>a0adfd4e6e617c21e9de8f9d006d143a</td>\n",
              "      <td>2021-04-09 23:37:09</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>770.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>55.768613</td>\n",
              "      <td>37.580378</td>\n",
              "      <td>55.732811</td>\n",
              "      <td>37.535191</td>\n",
              "      <td>Kia Rio</td>\n",
              "      <td>5.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Ставит прибытие, не доезжая до А\\nСтартует тач...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>86a1d75a3366f9ccf0dd95459ef36c58</td>\n",
              "      <td>c79d0c270adf8cfc92570ab608d228b4</td>\n",
              "      <td>a5832f040002a98f67c884cf0e507a67</td>\n",
              "      <td>2021-04-09 23:40:11</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>9.3</td>\n",
              "      <td>55.805612</td>\n",
              "      <td>37.522111</td>\n",
              "      <td>55.790116</td>\n",
              "      <td>37.496172</td>\n",
              "      <td>Toyota Camry</td>\n",
              "      <td>5.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>ef394c9f24453dd4e7d9a563a761f4d8</td>\n",
              "      <td>3694cb26b900e5bc06f0b3fd62e7897b</td>\n",
              "      <td>d48161326ee0534ffc2eebfc4a77f569</td>\n",
              "      <td>2021-04-09 23:42:47</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.9</td>\n",
              "      <td>24.2</td>\n",
              "      <td>55.709959</td>\n",
              "      <td>37.622206</td>\n",
              "      <td>55.780273</td>\n",
              "      <td>37.535656</td>\n",
              "      <td>Skoda Rapid</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270</th>\n",
              "      <td>010927d83eb31965dd0c63013ee125c4</td>\n",
              "      <td>09563133175aa456e9001c81dc331bdc</td>\n",
              "      <td>3f1c4dc975ec1464e7571c514cd707bc</td>\n",
              "      <td>2021-04-09 23:47:22</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>55.578766</td>\n",
              "      <td>37.665268</td>\n",
              "      <td>55.597149</td>\n",
              "      <td>37.666500</td>\n",
              "      <td>Kia Ceed</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>Прокуреный салон.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1271</th>\n",
              "      <td>10e746d36c1b153d891c6b892c175778</td>\n",
              "      <td>f135963189bc873430c69241a4fd4ff7</td>\n",
              "      <td>88d5c5c77575a78df92dd2b82af37569</td>\n",
              "      <td>2021-04-09 23:50:19</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>34.1</td>\n",
              "      <td>55.723518</td>\n",
              "      <td>37.610889</td>\n",
              "      <td>55.671089</td>\n",
              "      <td>37.855760</td>\n",
              "      <td>Kia Rio</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>Больше нечего сказать</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1272 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              order_id  ...                                            comment\n",
              "0     49430c6531d098d3b288d95d7d1e7f4f  ...                              Больше нечего сказать\n",
              "1     d3fff1a829a5b5ccbccd40c9895ff4b0  ...                              Больше нечего сказать\n",
              "2     f73533b8aab3b1d7b52488d954a46fa0  ...                                       Все отлично!\n",
              "3     43c6c249e4751b9ba0cf68de3e40a053  ...         Водитель чихает без маски не прикрывая нос\n",
              "4     b88dccdeaa7c5c1478915d7532082cda  ...                              Больше нечего сказать\n",
              "...                                ...  ...                                                ...\n",
              "1267  dde84eeec63c85f1a1dc1f5321c9d424  ...  Ставит прибытие, не доезжая до А\\nСтартует тач...\n",
              "1268  86a1d75a3366f9ccf0dd95459ef36c58  ...                              Больше нечего сказать\n",
              "1269  ef394c9f24453dd4e7d9a563a761f4d8  ...                              Больше нечего сказать\n",
              "1270  010927d83eb31965dd0c63013ee125c4  ...                                  Прокуреный салон.\n",
              "1271  10e746d36c1b153d891c6b892c175778  ...                              Больше нечего сказать\n",
              "\n",
              "[1272 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aS614MU2hD5"
      },
      "source": [
        "# result_series = pd.Series(model_semisupervised.predict(X_test))\n",
        "result_series = pd.Series(np.zeros(X_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2gV-eQg5Dyh"
      },
      "source": [
        "result_series.name = 'is_aggressive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foE2AsEA7o71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f62cddc-cb95-4d75-adde-8486a71ba429"
      },
      "source": [
        "result_series[5] = 1\n",
        "\n",
        "result_series"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.0\n",
              "1       0.0\n",
              "2       0.0\n",
              "3       0.0\n",
              "4       0.0\n",
              "       ... \n",
              "1267    0.0\n",
              "1268    0.0\n",
              "1269    0.0\n",
              "1270    0.0\n",
              "1271    0.0\n",
              "Name: is_aggressive, Length: 1272, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHkfSDJljoTL",
        "outputId": "94a68a6e-560d-4e74-812d-d123f5d86715"
      },
      "source": [
        "result_series.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY6Fcj883x9i"
      },
      "source": [
        "result_series.to_csv(\"result.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}