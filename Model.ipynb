{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):        \n",
    "        self.model = None\n",
    "        self.counter_words = {}\n",
    "    \n",
    "    def count_words(self, x):\n",
    "        return len(x.split(\" \"))\n",
    "\n",
    "    def check_sentence(self, sentence, words_type):\n",
    "        words_count = 0\n",
    "        for word in sentence.split(\" \"):\n",
    "            word = word.lower().replace(',', '').replace('.', '')\n",
    "\n",
    "            if (word not in list(self.counter_words.keys()) or len(self.counter_words[word]) == 2): continue\n",
    "\n",
    "            if (words_type == self.counter_words[word][2]): \n",
    "                words_count += 1\n",
    "        return words_count\n",
    "        \n",
    "    def NLP_preprocess(self, X ,y):\n",
    "        dataset_joined = X.join(y)\n",
    "        comment_phrases = list(dataset_joined.comment.value_counts().index[: 10])\n",
    "        \n",
    "        dataset_joined['is_comment'] = (~np.isin(dataset_joined.comment, comment_phrases)).astype(int)\n",
    "        \n",
    "        aggressive_comments = dataset_joined[(dataset_joined['is_comment'] == True) & (dataset_joined.is_aggressive == True)].comment.values\n",
    "        normal_comments = dataset_joined[(dataset_joined['is_comment'] == True) & (dataset_joined.is_aggressive == False)].comment.values\n",
    "        \n",
    "        stop_words = ['на', 'по', 'с', 'в', 'что', 'и', 'а']\n",
    "\n",
    "        for sentence in normal_comments:\n",
    "            for word in sentence.split(\" \"):\n",
    "                word = word.lower().replace(',', '').replace('.', '')\n",
    "                if (word in stop_words): continue\n",
    "                if (word in self.counter_words.keys()):\n",
    "                    self.counter_words[word][0] += 1\n",
    "                else: self.counter_words[word] = [1, 0]\n",
    "\n",
    "        for sentence in aggressive_comments:\n",
    "            for word in sentence.split(\" \"):\n",
    "                word = word.lower().replace(',', '').replace('.', '')\n",
    "                if (word in stop_words): continue\n",
    "                if (word in self.counter_words.keys()):\n",
    "                    self.counter_words[word][1] += 1\n",
    "                else: self.counter_words[word] = [0, 1]\n",
    "        \n",
    "        \n",
    "        count_all_words = np.array(list(map(lambda x: np.array(x), np.array(list(self.counter_words.items())).T[1]))).T\n",
    "        \n",
    "        count_normal_words = count_all_words[0].sum()\n",
    "        count_aggressive_words = count_all_words[1].sum()\n",
    "\n",
    "        for word_pair in list(self.counter_words.items()):\n",
    "            if (word_pair[1][1] == 0 and word_pair[1][0] > 0):\n",
    "                self.counter_words[word_pair[0]].append(\"normal\")\n",
    "                continue\n",
    "\n",
    "            if (word_pair[1][0] == 0 and word_pair[1][1] > 0):\n",
    "                self.counter_words[word_pair[0]].append(\"aggressive\")\n",
    "                continue\n",
    "\n",
    "            ratio_aggressive = word_pair[1][1] / count_aggressive_words\n",
    "            ratio_normal = word_pair[1][0] / count_normal_words\n",
    "\n",
    "            if (ratio_aggressive / ratio_normal >= 3):\n",
    "                self.counter_words[word_pair[0]].append(\"aggressive\")\n",
    "                continue\n",
    "\n",
    "            if (ratio_normal / ratio_aggressive >= 3):\n",
    "                self.counter_words[word_pair[0]].append(\"normal\")\n",
    "                continue\n",
    "\n",
    "            self.counter_words[word_pair[0]].append(\"neutral\")\n",
    "\n",
    "    def add_features(self, X):\n",
    "        comment_phrases = list(X.comment.value_counts().index[: 5]) + [\"---\"]\n",
    "        \n",
    "        X[\"is_comment\"] = (~np.isin(X.comment, comment_phrases)).astype(int)\n",
    "        X['dttm'] = pd.to_datetime(X.dttm)\n",
    "        X['hour'] = X.dttm.apply(lambda x: x.hour)\n",
    "        X['traff_jam'] = ((X.hour > 6) & (X.hour < 10)) | ((X.hour > 17) & (X.hour < 23))\n",
    "        X['traff_jam'] = X.traff_jam.astype(int)\n",
    "        X['weekday'] = X.dttm.apply(lambda x: x.weekday())\n",
    "        X['holiday'] = (X.weekday >= 5).astype(int)\n",
    "        X[\"count_words\"] = [-1] * X.shape[0]\n",
    "        X.loc[X.is_comment == True, \"count_words\"] = X[X.is_comment == True].comment.apply(lambda x: self.count_words(x))\n",
    "        X[\"speed\"] = X.distance / (X.duration / 60)\n",
    "        X['agg_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"aggressive\"))\n",
    "        X['normal_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"normal\"))\n",
    "        X['distance_thresh'] = ((X.distance > 5) & (X.distance < 20)).astype(int)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def estimate(self, X, y):\n",
    "        return roc_auc_score(y, self.predict_proba(X, add_feat=False))\n",
    "    \n",
    "    def train_test_split_(self, X, y, test_size, X_ss=None, y_ss=None, random_state=42):\n",
    "        if (X_ss is not None):\n",
    "            X_ss['ss'] = 1\n",
    "            y_ss = y_ss.to_frame()\n",
    "            y_ss['ss'] = 1\n",
    "            \n",
    "            X['ss'] = 0\n",
    "            y['ss'] = 0\n",
    "            \n",
    "            X_ss_full = pd.concat([X, X_ss]).sample(frac=1, random_state=random_state)\n",
    "            y_ss_full = pd.concat([y, y_ss]).sample(frac=1, random_state=random_state)\n",
    "            \n",
    "            len_train = len(X_ss_full) - round(len(X_ss_full) * test_size)\n",
    "            \n",
    "            x_train = X_ss_full[: len_train]\n",
    "            x_train.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            x_test = X_ss_full.iloc[len_train + 1:]\n",
    "            x_test = x_test[x_test.ss == 0]\n",
    "            x_test.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            y_train = y_ss_full[: len_train]\n",
    "            y_train.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            y_test = y_ss_full.iloc[len_train + 1:]\n",
    "            y_test = y_test[y_test.ss == 0]\n",
    "            y_test.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            return (x_train, x_test, y_train, y_test)\n",
    "        \n",
    "        len_train = len(X) - round(len(X) * test_size)\n",
    "        \n",
    "        X = X.sample(frac=1, random_state=random_state)\n",
    "        y = y.sample(frac=1, random_state=random_state)\n",
    "        \n",
    "        return (X[: len_train], X[len_train :], y[: len_train], y[len_train :])\n",
    "    \n",
    "    def train(self, X_train, X_test, y_train, y_test, categorical_features):\n",
    "        print(f\"Train size: {X_train.shape}\")\n",
    "        print(f\"Test size: {X_test.shape}\")\n",
    "        self.model = CatBoostClassifier(iterations=2000,\n",
    "                           depth=2,\n",
    "                           silent=True,\n",
    "                           loss_function='Logloss',\n",
    "                           class_weights=(1, 2),\n",
    "                           random_state=42)\n",
    "\n",
    "        self.model.fit(X_train, y_train, cat_features=categorical_features)\n",
    "        \n",
    "        return self.estimate(X_test, y_test)\n",
    "    \n",
    "    def fit_ss(self, X, y, numeric_features, categorial_features, X_ss, y_ss):\n",
    "        self.counter_words = {}\n",
    "        \n",
    "        X_ = X\n",
    "        y_ = y\n",
    "        \n",
    "        self.NLP_preprocess(pd.concat([X_, X_ss]), pd.concat([y_, y_ss]))\n",
    "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
    "        \n",
    "        X_ss = self.add_features(X_ss)[numeric_features + categorical_features]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, X_ss=X_ss, y_ss=y_ss, random_state=42)\n",
    "        \n",
    "        return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
    "    \n",
    "    def fit(self, X, y, numeric_features, categorial_features):\n",
    "        self.counter_words = {}\n",
    "        \n",
    "        X_ = X\n",
    "        y_ = y\n",
    "        \n",
    "        self.NLP_preprocess(X_, y_)\n",
    "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, random_state=42)\n",
    "\n",
    "        return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
    "    \n",
    "    def predict_proba(self, X, add_feat=True):\n",
    "        if (add_feat): X = self.add_features(X)\n",
    "        \n",
    "        X = X[numeric_features + categorical_features]\n",
    "        \n",
    "        return self.model.predict_proba(X).T[1]\n",
    "    \n",
    "    def predict_thresh(self, X, thresh_above, thresh_below):\n",
    "        y_unlab_full = self.predict_proba(X)\n",
    "        \n",
    "        y_unlab = pd.Series([-1 for i in range(len(X))])\n",
    "        \n",
    "        print(\"Thresh above: {}\".format(sum(y_unlab_full >= thresh_above) / len(y_unlab_full)))\n",
    "        print(\"Thresh below: {}\".format(sum(y_unlab_full <= thresh_below) / len(y_unlab_full)))\n",
    "        \n",
    "        y_unlab.iloc[np.where(y_unlab_full >= thresh_above)] = 1\n",
    "        y_unlab.iloc[np.where(y_unlab_full <= thresh_below)] = 0\n",
    "        \n",
    "        return y_unlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled = pd.read_csv('data/labled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
    "\n",
    "X_ = train_labeled.iloc[:, :-1]\n",
    "y_ = train_labeled.iloc[:, -1:]\n",
    "\n",
    "X_['client_rate_ride'] = X_['client_rate_ride'].fillna(X_['client_rate_ride'].mean())\n",
    "X_['client_rides_cnt'] = X_['client_rides_cnt'].fillna(X_['client_rides_cnt'].mean())\n",
    "X_['driver_rides_cnt'] = X_['driver_rides_cnt'].fillna(X_['driver_rides_cnt'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['distance', 'arrived_distance', 'arrived_duration', 'duration', 'driver_rides_cnt', 'client_rides_cnt', 'client_rate_ride', 'count_words']\n",
    "\n",
    "categorical_features = ['mark', 'is_comment', 'hour', 'weekday', 'agg_words', 'normal_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_supervised = Model()\n",
    "\n",
    "model_supervised.fit(X_, y_, numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlab = pd.read_csv('data/unlabled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
    "comments_unlabeled = pd.read_csv('data/unlabled_train_comments.csv', index_col=0, sep='\\t', comment='#')\n",
    "tracks_unlabeled = pd.read_csv('data/unlabled_train_tracks.csv', index_col=0, sep='\\t', comment='#')\n",
    "\n",
    "X_unlab['client_rate_ride'] = X_unlab['client_rate_ride'].fillna(X_unlab['client_rate_ride'].mean())\n",
    "X_unlab['client_rides_cnt'] = X_unlab['client_rides_cnt'].fillna(X_unlab['client_rides_cnt'].mean())\n",
    "X_unlab['driver_rides_cnt'] = X_unlab['driver_rides_cnt'].fillna(X_unlab['driver_rides_cnt'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(X_unlab.comment.isna())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nanIndex in np.where(X_unlab.comment.isna())[0]:\n",
    "    obj_comment = comments_unlabeled.loc[nanIndex]\n",
    "    \n",
    "    if (len(obj_comment) != 0):\n",
    "        X_unlab.comment.iloc[nanIndex] = obj_comment.comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlab.comment.iloc[np.where(X_unlab.comment.isna())[0]] = \"---\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction&filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unlab = model_supervised.predict_thresh(X_unlab, 0.99, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unlab.name = \"is_aggressive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unlab.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlab_lab = X_unlab.iloc[np.where(y_unlab != -1)]\n",
    "y_unlab_lab = y_unlab.iloc[np.where(y_unlab != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_unlab_lab.comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_semisupervised = Model()\n",
    "\n",
    "model_semisupervised.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
