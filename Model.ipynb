{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IcH7T4cJsOzL",
        "BZNrSHdSORxG",
        "tJA_bsAaORxI",
        "_fZL4rRiFCio",
        "GTkhnZoHx5JI",
        "UqEQmfo0x5JK",
        "oW92gZ9-x5JL"
      ],
      "machine_shape": "hm"
    },
    "interpreter": {
      "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install environment"
      ],
      "metadata": {
        "id": "IcH7T4cJsOzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RANDOM_STATE = 42\n",
        "COLAB = False # если на колабе то тру соответственно "
      ],
      "outputs": [],
      "metadata": {
        "id": "XsBW5f7rFx0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    !pip install catboost\n",
        "    !pip install sktime\n",
        "    !pip install tqdm"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT4V-uZiJFE-",
        "outputId": "489aa38e-fbb6-43d7-d850-2f2bc92d9d16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "from sktime.transformations.panel.rocket import MiniRocket\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ],
      "outputs": [],
      "metadata": {
        "id": "j1qmmvEyx5I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecde0fd-5e2d-49ef-8703-cebd5311c56a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model code"
      ],
      "metadata": {
        "id": "Zk2YRwe9ONnZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import datetime \n",
        "import pickle\n",
        "from math import cos, asin, sqrt, pi\n",
        "from tracks.tracks_preprocessing import Tracks_preprocessing\n",
        "from nlp.nlp_model import get_model\n",
        "from tsfresh import select_features\n",
        "\n",
        "# TODO: добавить фичи по превышению скорости, добавить фичи из нлп гены(он там все настроил уже по идее), натреинровать, затестить\n",
        "\n",
        "# formula using pythogorian theorem\n",
        "# (as distances are not large, we can approximate earth rounding)\n",
        "def get_distance(lat1,lon1,lat2,lon2):\n",
        "    delta_lat = pow(lat2-lat1,2)\n",
        "    delta_lon = pow(lon2-lon1,2)\n",
        "    return np.round(sqrt(delta_lat+delta_lon)*100, 3)    \n",
        "\n",
        "def get_speed(lat1, lon1, lat2, lon2, dt1: str, dt2: str) -> float:\n",
        "    distance = get_distance(lat1, lon1, lat2, lon2).tolist()\n",
        "    format = \"%Y-%m-%d %H:%M:%S\"\n",
        "    dt1=datetime.datetime.strptime(dt1, format)\n",
        "    dt2=datetime.datetime.strptime(dt2, format)\n",
        "    time = (dt2-dt1).total_seconds()/3600 # convert timedelta into hours\n",
        "    if time==0:\n",
        "        return 0\n",
        "    return distance/time\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):        \n",
        "        self.model = None\n",
        "        self.model_tracks = None\n",
        "\n",
        "        self.counter_words = {}\n",
        "    \n",
        "    def count_words(self, x):\n",
        "        return len(x.split(\" \"))\n",
        "\n",
        "    def check_sentence(self, sentence, words_type):\n",
        "        words_count = 0\n",
        "        for word in sentence.split(\" \"):\n",
        "            word = word.lower().replace(',', '').replace('.', '')\n",
        "\n",
        "            if (word not in list(self.counter_words.keys()) or len(self.counter_words[word]) == 2): continue\n",
        "\n",
        "            if (words_type == self.counter_words[word][2]): \n",
        "                words_count += 1\n",
        "        return words_count\n",
        "        \n",
        "    def NLP_features(self, X: pd.DataFrame,y:pd.DataFrame,comments: pd.DataFrame):\n",
        "        self.NLP_model, result = get_model(X,y, comments)\n",
        "        self.nlp_features=result\n",
        "        return result\n",
        "\n",
        "    def add_features(self, X):\n",
        "        comment_phrases = list(X.comment.value_counts().index[: 5]) + [\"---\"]\n",
        "        \n",
        "        X[\"is_comment\"] = (~np.isin(X.comment, comment_phrases)).astype(int)\n",
        "        X['dttm'] = pd.to_datetime(X.dttm)\n",
        "        X['hour'] = X.dttm.apply(lambda x: x.hour)\n",
        "        X['traff_jam'] = ((X.hour > 6) & (X.hour < 10)) | ((X.hour > 17) & (X.hour < 23))\n",
        "        X['traff_jam'] = X.traff_jam.astype(int)\n",
        "        X['weekday'] = X.dttm.apply(lambda x: x.weekday())\n",
        "        X['holiday'] = (X.weekday >= 5).astype(int)\n",
        "        X[\"count_words\"] = [-1] * X.shape[0]\n",
        "        X.loc[X.is_comment == True, \"count_words\"] = X[X.is_comment == True].comment.apply(lambda x: self.count_words(x))\n",
        "        X[\"speed\"] = X.distance / (X.duration / 60)\n",
        "        X['agg_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"aggressive\"))\n",
        "        X['normal_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"normal\"))\n",
        "        X['distance_thresh'] = ((X.distance > 5) & (X.distance < 20)).astype(int)\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def gen_speed(self, tracks):\n",
        "        tracks['speed'] = np.zeros(tracks.shape[0])\n",
        "        for i in tqdm(range(1, len(tracks))):\n",
        "            tracks.iloc[i, tracks.columns.get_loc('speed')] = get_speed(tracks.iloc[i-1, tracks.columns.get_loc('lat_')], tracks.iloc[i-1, tracks.columns.get_loc('lon_')],\n",
        "                                        tracks.iloc[i, tracks.columns.get_loc('lat_')], tracks.iloc[i, tracks.columns.get_loc('lon_')], tracks.iloc[i-1, tracks.columns.get_loc('dt')], tracks.iloc[i, tracks.columns.get_loc('dt')])\n",
        "        return tracks\n",
        "    \n",
        "    def estimate(self, X, y):\n",
        "        print('ESTIMATION')\n",
        "        return roc_auc_score(y, self.model.predict_proba(X).T[1])\n",
        "    \n",
        "    def train_test_split_(self, X, y, test_size, X_ss=None, y_ss=None, random_state=RANDOM_STATE):\n",
        "        assert X.shape[0] == y.shape[0]\n",
        "        if (X_ss is not None):\n",
        "            X_ss_full, y_ss_full = self.label_shuffle(X, y, X_ss, y_ss, random_state = random_state)\n",
        "            \n",
        "            len_train = len(X_ss_full) - round(len(X_ss_full) * test_size)\n",
        "            \n",
        "            x_train = X_ss_full[: len_train]\n",
        "            x_train.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            x_test = X_ss_full.iloc[len_train + 1:]\n",
        "            x_test = x_test[x_test.ss == 0]\n",
        "            x_test.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            y_train = y_ss_full[: len_train]\n",
        "            y_train.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            y_test = y_ss_full.iloc[len_train + 1:]\n",
        "            y_test = y_test[y_test.ss == 0]\n",
        "            y_test.drop('ss', axis = 1, inplace = True)\n",
        "            \n",
        "            return (x_train, x_test, y_train, y_test)\n",
        "        \n",
        "        len_train = len(X) - round(len(X) * test_size)\n",
        "        \n",
        "        X = X.sample(frac=1, random_state=random_state)\n",
        "        y = y.sample(frac=1, random_state=random_state)\n",
        "        \n",
        "        return (X[: len_train], X[len_train :], y[: len_train], y[len_train :])\n",
        "    \n",
        "    def train(self, X_train, X_test, y_train, y_test, categorical_feature, random_state=RANDOM_STATE):\n",
        "        print(f\"Train size: {X_train.shape}\")\n",
        "        print(f\"Test size: {X_test.shape}\")\n",
        "        print(f'TRAIN HEAD: \\n {X_train.head()}')\n",
        "\n",
        "        print('y_TRAIN')\n",
        "        print(y_train.head())\n",
        "        print('X_TRAIN')\n",
        "        print(X_train.head())\n",
        "        non_aggressive = len(y_train)-sum(y_train)\n",
        "        aggressive = sum(y_train)\n",
        "        class_weights = (1, int(non_aggressive/aggressive))\n",
        "\n",
        "        self.model = CatBoostClassifier(iterations=4000,\n",
        "                           depth=3,\n",
        "                           silent=False,\n",
        "                           loss_function='Logloss',\n",
        "                           class_weights=class_weights,\n",
        "                           random_state=random_state)\n",
        "        #self.model.select_features(X_train, y_train,(X_test, y_test), features_for_select = '')\n",
        "        print(categorical_feature)\n",
        "        self.model.fit(X_train, y_train, cat_features=X_train.select_dtypes(include=['category', 'object']).columns.tolist(), save_snapshot=True,)\n",
        "        main_model_path = './model.pkl'\n",
        "        with open(main_model_path, 'wb') as f:\n",
        "            pickle.dump(self.model, f)\n",
        "        \n",
        "        print(y_test.shape)\n",
        "\n",
        "        return self.estimate(X_test, y_test)\n",
        "    \n",
        "    def label_shuffle(self, X, y, X_ss, y_ss, random_state=RANDOM_STATE):\n",
        "        X_ss['ss'] = 1\n",
        "        y_ss = y_ss.to_frame()\n",
        "        y_ss['ss'] = 1\n",
        "\n",
        "        X['ss'] = 0\n",
        "        y['ss'] = 0\n",
        "\n",
        "        X_ss_full = pd.concat([X, X_ss]).sample(frac=1, random_state=random_state)\n",
        "        y_ss_full = pd.concat([y, y_ss]).sample(frac=1, random_state=random_state)\n",
        "        \n",
        "        return (X_ss_full, y_ss_full)\n",
        "    \n",
        "    def train_cross_validation(self, X, y, k, categorical_features, X_ss=None, y_ss=None, random_state=RANDOM_STATE):\n",
        "        chunk_size = len(X) / k\n",
        "        chunks_size = [(i*chunk_size, i*chunk_size + chunk_size) for i in range(k)]\n",
        "        \n",
        "        result_score = []\n",
        "        \n",
        "        print(f\"Part size: {chunk_size}\")\n",
        "        \n",
        "        if (X_ss is not None):\n",
        "            X_ss_full, y_ss_full = self.label_shuffle(X, y, X_ss, y_ss, random_state = random_state)\n",
        "            \n",
        "            for chunkIndex in range(len(chunks_size)):\n",
        "                x_test = X_ss_full[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                y_test = y_ss_full[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                \n",
        "                x_train = X_ss_full.drop(x_test.index, axis = 0)\n",
        "                y_train = y_ss_full.drop(y_test.index, axis = 0)\n",
        "                \n",
        "                x_test = x_test[x_test.ss == 0]\n",
        "                y_test = y_test[y_test.ss == 0]\n",
        "                \n",
        "                x_train.drop('ss', axis = 1, inplace = True)\n",
        "                y_train.drop('ss', axis = 1, inplace = True)\n",
        "                x_test.drop('ss', axis = 1, inplace = True)\n",
        "                y_test.drop('ss', axis = 1, inplace = True)\n",
        "                \n",
        "                score = self.train(x_train, x_test, y_train, y_test, categorical_features)\n",
        "                \n",
        "                print(f\"Chunk {chunkIndex}; Score: {score}\")\n",
        "                \n",
        "                result_score.append((chunks_size[chunkIndex], score))\n",
        "        else:            \n",
        "            for chunkIndex in range(len(chunks_size)):\n",
        "                x_test = X[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                y_test = y[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
        "                \n",
        "                x_train = X.drop(x_test.index, axis = 0)\n",
        "                y_train = y.drop(y_test.index, axis = 0)\n",
        "                \n",
        "                score = self.train(x_train, x_test, y_train, y_test, categorical_features)\n",
        "                \n",
        "                print(f\"Chunk {chunkIndex}; Score: {score}\")\n",
        "                \n",
        "                result_score.append((chunks_size[chunkIndex], score))\n",
        "            \n",
        "        print(f\"Mean score: {sum(list(map(lambda x: x[1], result_score))) / k}\")\n",
        "        \n",
        "        return result_score\n",
        "    \n",
        "    def fit_ss(self, X, y, numeric_features, categorial_features, X_ss, y_ss, cross_validation=False, random_state=RANDOM_STATE):\n",
        "        self.counter_words = {}\n",
        "        \n",
        "        X_ = X\n",
        "        y_ = y\n",
        "        \n",
        "        self.NLP_preprocess(pd.concat([X_, X_ss]), pd.concat([y_, y_ss]))\n",
        "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
        "        \n",
        "        X_ss = self.add_features(X_ss)\n",
        "        \n",
        "        if (not cross_validation):\n",
        "            X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, X_ss=X_ss, y_ss=y_ss, random_state=random_state)\n",
        "            return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
        "        else:\n",
        "            return self.train_cross_validation(X_, y_, 5, categorical_features, X_ss=X_ss, y_ss=y_ss, random_state=random_state)\n",
        "        \n",
        "    def transform(self, X:pd.DataFrame, tracks:pd.DataFrame, comm_dataset:pd.DataFrame, is_training = True,random_state=RANDOM_STATE):\n",
        "        if tracks is not None:\n",
        "            preprocessing = Tracks_preprocessing() \n",
        "            if is_training:\n",
        "                tracks_train, tracks_y_train = preprocessing.preprocess(tracks)\n",
        "            else:\n",
        "                tracks_train = preprocessing.preprocess_unlabeled(tracks)\n",
        "        \n",
        "        self.counter_words = {}\n",
        "        \n",
        "        X_ = X.set_index('order_id').drop('is_aggressive', axis=1)\n",
        "        if is_training:\n",
        "            y_ = tracks_y_train\n",
        "        else:\n",
        "            y_=None\n",
        "        X_ = self.add_features(X_)\n",
        "\n",
        "        if is_training:\n",
        "            features = self.NLP_features(X_, y_,comm_dataset)\n",
        "        else:\n",
        "            features = self.NLP_model.features(X_, None)\n",
        "        X_ = X_.merge(features, on='order_id', how='left')\n",
        "        print(X_.head())\n",
        "\n",
        "        print(f\"Table data matrix shape: {X_.shape}\")\n",
        "        print(f\"Tracks data matrix shape: {tracks_train.shape}\")\n",
        "        # у датасета в виде индекса ордер айди, колонки - фичи заказа\n",
        "        res_matrix = tracks_train.merge(X_, right_index=True,left_index=True)\n",
        "        print('RES MATRIX')\n",
        "        print(res_matrix)\n",
        "        res_matrix.fillna(0, inplace=True)\n",
        "\n",
        "        print(f\"Result matrix shape: {res_matrix.shape}\")\n",
        "        # if tracks is not None:\n",
        "        #     # TODO: не подготовлено к предикту(нельзя обработать unlabled дату)\n",
        "        #     preprocessing = Tracks_preprocessing() \n",
        "        #     if is_training:\n",
        "        #         tracks_train, tracks_y_train = preprocessing.preprocess(tracks)\n",
        "        #     else:\n",
        "        #         tracks_train =preprocessing.preprocess_unlabeled(tracks)\n",
        "        # y_ = pd.DataFrame(tracks_y_train, columns=['is_aggressive']) if is_training else None\n",
        "\n",
        "        # self.counter_words = {}\n",
        "        # X_ = X.set_index('order_id')\n",
        "        # print(X_.columns)\n",
        "        # global_features = self.add_features(X_)\n",
        "        # X_ = X_.drop(['is_aggressive', 'from_longitude', 'to_longitude', 'from_latitude', 'to_latitude'], axis=1)\n",
        "        # print(X_.columns)\n",
        "        # print(X_.isnull().any())\n",
        "        # if is_training:\n",
        "        #     print()\n",
        "        #     features = self.NLP_features(X_,y_, comm_dataset)\n",
        "        # else:\n",
        "        #     features=self.NLP_model.features(X,comm_dataset)\n",
        "        # X_ = X_.merge(global_features, on='order_id')\n",
        "        # X_ = X_.merge(features, on='order_id')\n",
        "        # print(X_.head())\n",
        "\n",
        "        # print(f\"Table data matrix shape: {X_.shape}\")\n",
        "        # print(f\"Tracks data matrix shape: {tracks_train.shape}\")\n",
        "        # # у датасета в виде индекса ордер айди, колонки - фичи заказа\n",
        "        # res_matrix = tracks_train.merge(X_, right_index=True,left_index=True)\n",
        "        # print('RES MATRIX')\n",
        "        # print(res_matrix)\n",
        "        # res_matrix.fillna(0, inplace=True)\n",
        "        # #res_matrix = select_features(res_matrix, y_)\n",
        "        # #res_matrix.drop(['order_id'], axis=1, inplace=True)\n",
        "\n",
        "        # print(f\"Result matrix shape: {res_matrix.shape}\")\n",
        "        return res_matrix\n",
        "\n",
        "\n",
        "    def fit(self, X:pd.DataFrame, comments:pd.DataFrame, numeric_features, categorical_features, tracks:pd.DataFrame = None, cross_validation=False, random_state=RANDOM_STATE):\n",
        "\n",
        "        res_matrix = self.transform(X, tracks,comments, random_state,True)\n",
        "\n",
        "        if (not cross_validation):\n",
        "            X_train, X_test, y_train, y_test = self.train_test_split_(res_matrix, y_, test_size=0.3, random_state=random_state)\n",
        "            return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
        "        else:\n",
        "            return self.train_cross_validation(X_, y_, 5, categorical_features, random_state=random_state)\n",
        "\n",
        "    def predict_proba(self, X, add_feat=True, tracks=None):\n",
        "        # не доделано еще\n",
        "        if (add_feat): X = self.add_features(X)\n",
        "        \n",
        "        X = self.add_features(X)[numeric_features + categorical_features + [\"order_id\"]]\n",
        "\n",
        "        res_matrix = X.merge(tracks_train, how='left', on='order_id')\n",
        "        res_matrix.fillna(0, inplace=True)\n",
        "        res_matrix.drop(['order_id'], axis=1, inplace=True)\n",
        "\n",
        "        return self.model.predict_proba(res_matrix).T[1]\n",
        "    \n",
        "    def predict(self, X,comm_dataset, tracks=None):\n",
        "        # не готово \n",
        "        res_matrix=self.transform(X,tracks,comm_dataset,is_training=False)\n",
        "        \n",
        "        return self.model.predict(res_matrix)\n",
        "    \n",
        "    def predict_thresh(self, X, thresh_above, thresh_below):\n",
        "        y_unlab_full = self.predict_proba(X)\n",
        "        \n",
        "        y_unlab = pd.Series([-1 for i in range(len(X))])\n",
        "        \n",
        "        print(\"Thresh above: {}\".format(sum(y_unlab_full >= thresh_above) / len(y_unlab_full)))\n",
        "        print(\"Thresh below: {}\".format(sum(y_unlab_full <= thresh_below) / len(y_unlab_full)))\n",
        "        \n",
        "        y_unlab.iloc[np.where(y_unlab_full >= thresh_above)] = 1\n",
        "        y_unlab.iloc[np.where(y_unlab_full <= thresh_below)] = 0\n",
        "        \n",
        "        return y_unlab\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/porosenok/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "metadata": {
        "id": "73bPA-Pcx5JA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on labled data"
      ],
      "metadata": {
        "id": "fbSXf2PYx5JF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "if COLAB:\n",
        "    path = '/content/drive/MyDrive/aiijc_transport_simpleteam/'\n",
        "else:\n",
        "    path = './'\n",
        "\n",
        "train_labled = pd.read_csv(path + 'data/base_files/labled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_labled = pd.read_csv(path+\"data/labled_train_tracks_speed.csv\", index_col=0, sep=',', comment='#')\n",
        "tracks_unlabled = pd.read_csv(path +\"data/unlabled_train_tracks_speed.csv\", index_col=0, sep=',', comment='#')\n",
        "\n",
        "labled_train_comments = pd.read_csv('data/base_files/labled_train_comments.csv', comment='#', sep='\\t').drop('Unnamed: 0', axis=1)\n",
        "\n",
        "\n",
        "X_ = train_labled\n",
        "print(X_.columns)\n",
        "#y_ = train_labled.iloc[:, -1:]\n",
        "\n",
        "X_['client_rate_ride'] = X_['client_rate_ride'].fillna(X_['client_rate_ride'].mean())\n",
        "X_['client_rides_cnt'] = X_['client_rides_cnt'].fillna(X_['client_rides_cnt'].mean())\n",
        "X_['driver_rides_cnt'] = X_['driver_rides_cnt'].fillna(X_['driver_rides_cnt'].mean())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['order_id', 'driver_id', 'client_id', 'dttm', 'date',\n",
            "       'arrived_distance', 'arrived_duration', 'distance', 'duration',\n",
            "       'from_latitude', 'from_longitude', 'to_latitude', 'to_longitude',\n",
            "       'mark', 'client_rate_ride', 'client_rides_cnt', 'driver_rides_cnt',\n",
            "       'comment', 'is_aggressive'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "metadata": {
        "id": "roi11zG3x5JF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "labled_train_comments = labled_train_comments.fillna('Больше нечего сказать'.lower())"
      ],
      "outputs": [],
      "metadata": {
        "id": "kFkCdcz_CHyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "numeric_features = ['distance', 'arrived_distance', 'arrived_duration', 'duration', 'driver_rides_cnt', 'client_rides_cnt', 'client_rate_ride', 'count_words']\n",
        "\n",
        "categorical_features = ['mark', 'is_comment', 'hour', 'weekday', 'agg_words', 'normal_words']\n",
        "model_supervised = Model()\n",
        "\n",
        "model_supervised.fit(X_, labled_train_comments, numeric_features, categorical_features, tracks=tracks_labled)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training vectorizer model...\n",
            "TEXT WECTORIZER TRAINED\n",
            "training vectorizer model...\n",
            "CARS WECTORIZER TRAINED\n",
            "training cars clustering model...\n",
            "CARS CLUSTERING COMPLETED\n",
            "driver_id           False\n",
            "client_id           False\n",
            "dttm                False\n",
            "date                False\n",
            "arrived_distance    False\n",
            "arrived_duration    False\n",
            "distance            False\n",
            "duration            False\n",
            "from_latitude       False\n",
            "from_longitude      False\n",
            "to_latitude         False\n",
            "to_longitude        False\n",
            "mark                False\n",
            "client_rate_ride    False\n",
            "client_rides_cnt    False\n",
            "driver_rides_cnt    False\n",
            "comment             False\n",
            "is_comment          False\n",
            "hour                False\n",
            "traff_jam           False\n",
            "weekday             False\n",
            "holiday             False\n",
            "count_words         False\n",
            "speed               False\n",
            "agg_words           False\n",
            "normal_words        False\n",
            "distance_thresh     False\n",
            "dtype: bool\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0ccd069b3c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_supervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabled_train_comments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracks_labled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-4f776d0823fe>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, comments, numeric_features, categorical_features, tracks, cross_validation, random_state)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mres_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4f776d0823fe>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, tracks, comm_dataset, is_training, random_state)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLP_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLP_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4f776d0823fe>\u001b[0m in \u001b[0;36mNLP_features\u001b[0;34m(self, X, y, comments)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mNLP_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLP_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/programming/ML/aiijc/aijic2021_transport/nlp/nlp_model.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(X, y, comments)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm_dataset_labled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/programming/ML/aiijc/aijic2021_transport/nlp/nlp_model.py\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(self, X, y, comm_dataset_labled, comm_dataset_unlabled)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cars_vectorizer_and_clusterer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# тренировка doc2vec модели и кластеризации для машин\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_comm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# тренировка модели вероятностей агрессивности текстов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mX_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomm_dataset_labled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/programming/ML/aiijc/aijic2021_transport/nlp/nlp_model.py\u001b[0m in \u001b[0;36mtrain_comm_model\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_aggressive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COMM MODEL TRAINED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "metadata": {
        "id": "l5W_90wZx5JG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "predictions = model_supervised.predict(X_,comm_dataset=None,tracks=tracks_labled) # не готово"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Model' object has no attribute 'tracks_transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-536469c7e213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_supervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracks_labled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-6f5160b380db>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, add_feat, tracks)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madd_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtracks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mtracks_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracks_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mtracks_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mtracks_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracks_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'tracks_transform'"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIM7vNo4Uw-i",
        "outputId": "9982f0cc-b83d-4707-aa59-e136684bf63e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "predictions.sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcDiAhYaYXlx",
        "outputId": "1f3215e9-5f2c-416c-8a82-6fdb65cbc7f6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_cv = Model()\n",
        "\n",
        "model_cv.fit(X_, y_, numeric_features, categorical_features, cross_validation = True)"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": false,
        "id": "TBM0T9fax5JH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi-supervised train"
      ],
      "metadata": {
        "id": "PTweSMJMx5JH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "GTkhnZoHx5JI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_unlab = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/unlabled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "comments_unlabeled = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/unlabled_train_comments.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_unlabeled = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/unlabled_train_tracks.csv', index_col=0, sep='\\t', comment='#')\n",
        "\n",
        "X_unlab['client_rate_ride'] = X_unlab['client_rate_ride'].fillna(X_unlab['client_rate_ride'].mean())\n",
        "X_unlab['client_rides_cnt'] = X_unlab['client_rides_cnt'].fillna(X_unlab['client_rides_cnt'].mean())\n",
        "X_unlab['driver_rides_cnt'] = X_unlab['driver_rides_cnt'].fillna(X_unlab['driver_rides_cnt'].mean())"
      ],
      "outputs": [],
      "metadata": {
        "id": "faMhkd_2x5JI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.64866629360194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "murUE39Rx5JJ",
        "outputId": "70f08b78-8dac-4307-c4ad-8ed28793190d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.where(X_unlab.comment.isna())[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2762,  3239,  3574, ..., 10719, 10720, 10721])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9_4PR_xx5JJ",
        "outputId": "b239c8f3-424b-4815-cf7f-f770685f6afa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for nanIndex in np.where(X_unlab.comment.isna())[0]:\n",
        "    obj_comment = comments_unlabeled.loc[nanIndex]\n",
        "    \n",
        "    if (len(obj_comment) != 0):\n",
        "        X_unlab.comment.iloc[nanIndex] = obj_comment.comment"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": true,
        "id": "LTfgggjLx5JJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00018653236336504383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUvW5EXYx5JJ",
        "outputId": "6ce4fadd-d067-4cae-e1f9-25132348ea51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_unlab.comment.iloc[np.where(X_unlab.comment.isna())[0]] = \"---\""
      ],
      "outputs": [],
      "metadata": {
        "id": "2UH_STafx5JK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction&filling"
      ],
      "metadata": {
        "id": "UqEQmfo0x5JK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_unlab = model_supervised.predict_thresh(X_unlab, 0.99, 0.001)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresh above: 0.003357582540570789\n",
            "Thresh below: 0.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSEcB99Ex5JK",
        "outputId": "0b278408-1f90-4617-bf0d-b25381fc25ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_unlab.name = \"is_aggressive\""
      ],
      "outputs": [],
      "metadata": {
        "id": "I_hR7Co0x5JK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_unlab.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    10686\n",
              " 1       36\n",
              "Name: is_aggressive, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ],
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qKiVFbKx5JK",
        "outputId": "943ed4b0-8e91-40ed-955f-c82bb176e075"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_unlab_lab = X_unlab.iloc[np.where(y_unlab != -1)]\n",
        "y_unlab_lab = y_unlab.iloc[np.where(y_unlab != -1)]"
      ],
      "outputs": [],
      "metadata": {
        "id": "VcTdG9nWx5JL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_unlab_lab.comment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7        1)Водитель играл в «шашки» на дороге и игрался...\n",
              "202              2 раза списали деньги, верните пожалуйста\n",
              "351      засыпал за рулём,  съезжал с дороги, приходило...\n",
              "551               резкие повороты. водитель резко тормозил\n",
              "568      Водитель смотрит кино на втором телефоне, проп...\n",
              "705      Вел медленно по бордовым дорогам, сказал «пешк...\n",
              "1317     Водитель резко тормозил, обгонял, кричал на др...\n",
              "1378                             Водитель вел себя грубо. \n",
              "1634     Водитель постоянно громко разговаривал на своё...\n",
              "1667     Водитель в возрасте, несколько раз отвечал на ...\n",
              "1707     Водитель 2 раза поругался с другими таксистами...\n",
              "1975     Водитель опасно вел автомобиль. Было ощущение ...\n",
              "2221     Водитель явно засыпал за рулём, постоянно зева...\n",
              "2261      Приехала другая машина вместо указанной в заказе\n",
              "2302                       Водитель неадекватно себя вёл, \n",
              "2346     Проехал на красный свет дважды на перекрестках...\n",
              "2472                      водит опасно и очень неаккуратно\n",
              "2890                           Резкие повороты на скорости\n",
              "2926     Водитель ехал по выделенной полосе со скорость...\n",
              "3113     Водитель был не пристегнут, вульгарно общался ...\n",
              "3605     Опасное вождение, даже укачало. Отличался номе...\n",
              "3640     водительница очень резко тормозит каждый раз, ...\n",
              "3845     приехал не туда,пришлось идти ,прокурен салон ...\n",
              "3902     Водитель не нажал кнопку \"начать поездку\" и с ...\n",
              "4369     Не понимает когда человек говорить не хочет, г...\n",
              "4553     Не доехали до конечной точки. То ли ошибка при...\n",
              "4658     Грязно в машине ,сидения в пятнах ,резко тормо...\n",
              "5819     я первый раз в жизни ездила с таким водителем,...\n",
              "7431     Заехал на заправку не предупредив, хотя мы опа...\n",
              "8506     не смогла перевести деньги. водитель позвоните...\n",
              "8660              Водитель создал аварийную ситуацию !!!! \n",
              "8837                    почему от меня личный деньги снял,\n",
              "9021     Водитель постоянно открывал дверь и харкал; ма...\n",
              "9862     ужасно медленный водитель, ехал 40-50 км в час...\n",
              "10369    водитель хамит, постоянно переписывается в мес...\n",
              "10711    высадил меня прямо посреди большой лужи со сне...\n",
              "Name: comment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ],
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz7y4knWx5JL",
        "outputId": "368b8e8c-6e05-4de5-bbc3-f7c8fc6ead77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_unlab_lab.is_comment.value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    36\n",
              "Name: is_comment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kETFZg8x5JL",
        "outputId": "66154712-a8b9-4a42-e0c3-9c77639423f8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "oW92gZ9-x5JL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_semisupervised = Model()\n",
        "\n",
        "model_semisupervised.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: (7229, 14)\n",
            "Test size: (1798, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8488724212067151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ],
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKxX4spJx5JM",
        "outputId": "34cde40f-1bff-4222-de55-67c2e9ef09e5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_ss_cv = Model()\n",
        "\n",
        "model_ss_cv.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab, cross_validation=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part size: 1800.0\n",
            "Train size: (7224, 14)\n",
            "Test size: (1791, 14)\n",
            "Chunk 0; Score: 0.7396306537625914\n",
            "Train size: (7228, 14)\n",
            "Test size: (1797, 14)\n",
            "Chunk 1; Score: 0.742049078955933\n",
            "Train size: (7224, 14)\n",
            "Test size: (1794, 14)\n",
            "Chunk 2; Score: 0.7889097744360902\n",
            "Train size: (7225, 14)\n",
            "Test size: (1790, 14)\n",
            "Chunk 3; Score: 0.7370420937809273\n",
            "Train size: (7226, 14)\n",
            "Test size: (1792, 14)\n",
            "Chunk 4; Score: 0.85435199720914\n",
            "Mean score: 0.7723967196289363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0.0, 1800.0), 0.7396306537625914),\n",
              " ((1800.0, 3600.0), 0.742049078955933),\n",
              " ((3600.0, 5400.0), 0.7889097744360902),\n",
              " ((5400.0, 7200.0), 0.7370420937809273),\n",
              " ((7200.0, 9000.0), 0.85435199720914)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QuIHA4Ux5JM",
        "outputId": "ef68e8cb-f1a5-4175-bf3f-e0a62b4c5d6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "7riHsyVAzwLC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_test = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/labled_test_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_test = pd.read_csv('/content/drive/MyDrive/aiijc_transport_simpleteam/data/base_files/labled_test_tracks.csv', index_col=0, sep='\\t', comment='#')"
      ],
      "outputs": [],
      "metadata": {
        "id": "RsJBImFvzvoy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tracks_test.groupby('order_id').size()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "order_id\n",
              "000d9cf4365ad8be9b559951d0d945c7     12\n",
              "00287e34dd884a2a69c80346541d2aef     64\n",
              "00307c7812842b1159781c2c6375944a     41\n",
              "0061e7abbe5544c40781ba2816b3e026     61\n",
              "0074b0c828084e05c28035487ad2a130     82\n",
              "                                   ... \n",
              "ff209045501b1f25e8729a96a215a3d2     97\n",
              "ff4c5997ed87ff37a3c215bab2c0916e     49\n",
              "ff6873cfaccafec937bbed29e317d3e2     91\n",
              "ff9745e14cda84a4550b528a8d9aa4de    103\n",
              "ffd2c55165c42430793423c93211bd46     53\n",
              "Length: 1272, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvU1xokzB_th",
        "outputId": "9547275e-40b1-47f6-b0e1-d35ea8318266"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series = pd.Series(model_supervised.predict(X_test, add_feat=True, tracks=tracks_test))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing tracks data...\n",
            "    Begin shape: (71432, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1272/1272 [00:09<00:00, 133.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Shape after preprocessing: (1966, 1)\n",
            "Training MiniRocket...\n",
            "MiniRocket transforming...\n",
            "    Shape before transform: (1966, 1)\n"
          ]
        }
      ],
      "metadata": {
        "id": "876gjCvrCBQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b03573-e227-4dc9-adee-77c198074629"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series.sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 415
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8b3DVpabnZS",
        "outputId": "c1e09beb-4120-4943-c435-9b3517c3e965"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series = pd.Series(model_supervised.predict(X_test))\n",
        "# result_series = pd.Series(model_semisupervised.predict(X_test))\n",
        "# result_series = pd.Series(np.zeros(X_test.shape[0]))"
      ],
      "outputs": [],
      "metadata": {
        "id": "0aS614MU2hD5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series.shape[0], tracks_result.shape[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1272, 1966)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 367
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPxCWjMYEezH",
        "outputId": "eb1d1a46-eede-4ac8-b5b1-febe94ad404a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "abs(tracks_result - result_series)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-348-69677e227d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks_result\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mresult_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         result = ops.maybe_dispatch_ufunc_to_dunder_op(\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/roperator.py\u001b[0m in \u001b[0;36mrsub\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1966,) (1272,) "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "6IbXwtrfCkB5",
        "outputId": "7bdf6967-e382-4386-dfe3-9671d49f2960"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series.name = 'is_aggressive'"
      ],
      "outputs": [],
      "metadata": {
        "id": "w2gV-eQg5Dyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series.sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHkfSDJljoTL",
        "outputId": "6fc4dc61-8d83-45c3-fc29-4e9085f185f2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result_series.to_csv(\"result.csv\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "pY6Fcj883x9i"
      }
    }
  ]
}