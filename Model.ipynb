{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):        \n",
    "        self.model = None\n",
    "        self.counter_words = {}\n",
    "    \n",
    "    def count_words(self, x):\n",
    "        return len(x.split(\" \"))\n",
    "\n",
    "    def check_sentence(self, sentence, words_type):\n",
    "        words_count = 0\n",
    "        for word in sentence.split(\" \"):\n",
    "            word = word.lower().replace(',', '').replace('.', '')\n",
    "\n",
    "            if (word not in list(self.counter_words.keys()) or len(self.counter_words[word]) == 2): continue\n",
    "\n",
    "            if (words_type == self.counter_words[word][2]): \n",
    "                words_count += 1\n",
    "        return words_count\n",
    "        \n",
    "    def NLP_preprocess(self, X ,y):\n",
    "        dataset_joined = X.join(y)\n",
    "        comment_phrases = list(dataset_joined.comment.value_counts().index[: 10])\n",
    "        \n",
    "        dataset_joined['is_comment'] = (~np.isin(dataset_joined.comment, comment_phrases)).astype(int)\n",
    "        \n",
    "        aggressive_comments = dataset_joined[(dataset_joined['is_comment'] == True) & (dataset_joined.is_aggressive == True)].comment.values\n",
    "        normal_comments = dataset_joined[(dataset_joined['is_comment'] == True) & (dataset_joined.is_aggressive == False)].comment.values\n",
    "        \n",
    "        stop_words = ['на', 'по', 'с', 'в', 'что', 'и', 'а']\n",
    "\n",
    "        for sentence in normal_comments:\n",
    "            for word in sentence.split(\" \"):\n",
    "                word = word.lower().replace(',', '').replace('.', '')\n",
    "                if (word in stop_words): continue\n",
    "                if (word in self.counter_words.keys()):\n",
    "                    self.counter_words[word][0] += 1\n",
    "                else: self.counter_words[word] = [1, 0]\n",
    "\n",
    "        for sentence in aggressive_comments:\n",
    "            for word in sentence.split(\" \"):\n",
    "                word = word.lower().replace(',', '').replace('.', '')\n",
    "                if (word in stop_words): continue\n",
    "                if (word in self.counter_words.keys()):\n",
    "                    self.counter_words[word][1] += 1\n",
    "                else: self.counter_words[word] = [0, 1]\n",
    "        \n",
    "        \n",
    "        count_all_words = np.array(list(map(lambda x: np.array(x), np.array(list(self.counter_words.items())).T[1]))).T\n",
    "        \n",
    "        count_normal_words = count_all_words[0].sum()\n",
    "        count_aggressive_words = count_all_words[1].sum()\n",
    "\n",
    "        for word_pair in list(self.counter_words.items()):\n",
    "            if (word_pair[1][1] == 0 and word_pair[1][0] > 0):\n",
    "                self.counter_words[word_pair[0]].append(\"normal\")\n",
    "                continue\n",
    "\n",
    "            if (word_pair[1][0] == 0 and word_pair[1][1] > 0):\n",
    "                self.counter_words[word_pair[0]].append(\"aggressive\")\n",
    "                continue\n",
    "\n",
    "            ratio_aggressive = word_pair[1][1] / count_aggressive_words\n",
    "            ratio_normal = word_pair[1][0] / count_normal_words\n",
    "\n",
    "            if (ratio_aggressive / ratio_normal >= 3):\n",
    "                self.counter_words[word_pair[0]].append(\"aggressive\")\n",
    "                continue\n",
    "\n",
    "            if (ratio_normal / ratio_aggressive >= 3):\n",
    "                self.counter_words[word_pair[0]].append(\"normal\")\n",
    "                continue\n",
    "\n",
    "            self.counter_words[word_pair[0]].append(\"neutral\")\n",
    "\n",
    "    def add_features(self, X):\n",
    "        comment_phrases = list(X.comment.value_counts().index[: 5]) + [\"---\"]\n",
    "        \n",
    "        X[\"is_comment\"] = (~np.isin(X.comment, comment_phrases)).astype(int)\n",
    "        X['dttm'] = pd.to_datetime(X.dttm)\n",
    "        X['hour'] = X.dttm.apply(lambda x: x.hour)\n",
    "        X['traff_jam'] = ((X.hour > 6) & (X.hour < 10)) | ((X.hour > 17) & (X.hour < 23))\n",
    "        X['traff_jam'] = X.traff_jam.astype(int)\n",
    "        X['weekday'] = X.dttm.apply(lambda x: x.weekday())\n",
    "        X['holiday'] = (X.weekday >= 5).astype(int)\n",
    "        X[\"count_words\"] = [-1] * X.shape[0]\n",
    "        X.loc[X.is_comment == True, \"count_words\"] = X[X.is_comment == True].comment.apply(lambda x: self.count_words(x))\n",
    "        X[\"speed\"] = X.distance / (X.duration / 60)\n",
    "        X['agg_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"aggressive\"))\n",
    "        X['normal_words'] = X.comment.apply(lambda x: self.check_sentence(x, \"normal\"))\n",
    "        X['distance_thresh'] = ((X.distance > 5) & (X.distance < 20)).astype(int)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def estimate(self, X, y):\n",
    "        return roc_auc_score(y, self.predict_proba(X, add_feat=False))\n",
    "    \n",
    "    def train_test_split_(self, X, y, test_size, X_ss=None, y_ss=None, random_state=42):\n",
    "        if (X_ss is not None):\n",
    "            X_ss_full, y_ss_full = self.label_shuffle(X, y, X_ss, y_ss, random_state = random_state)\n",
    "            \n",
    "            len_train = len(X_ss_full) - round(len(X_ss_full) * test_size)\n",
    "            \n",
    "            x_train = X_ss_full[: len_train]\n",
    "            x_train.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            x_test = X_ss_full.iloc[len_train + 1:]\n",
    "            x_test = x_test[x_test.ss == 0]\n",
    "            x_test.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            y_train = y_ss_full[: len_train]\n",
    "            y_train.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            y_test = y_ss_full.iloc[len_train + 1:]\n",
    "            y_test = y_test[y_test.ss == 0]\n",
    "            y_test.drop('ss', axis = 1, inplace = True)\n",
    "            \n",
    "            return (x_train, x_test, y_train, y_test)\n",
    "        \n",
    "        len_train = len(X) - round(len(X) * test_size)\n",
    "        \n",
    "        X = X.sample(frac=1, random_state=random_state)\n",
    "        y = y.sample(frac=1, random_state=random_state)\n",
    "        \n",
    "        return (X[: len_train], X[len_train :], y[: len_train], y[len_train :])\n",
    "    \n",
    "    def train(self, X_train, X_test, y_train, y_test, categorical_features):\n",
    "        print(f\"Train size: {X_train.shape}\")\n",
    "        print(f\"Test size: {X_test.shape}\")\n",
    "        self.model = CatBoostClassifier(iterations=2000,\n",
    "                           depth=2,\n",
    "                           silent=True,\n",
    "                           loss_function='Logloss',\n",
    "                           class_weights=(1, 2),\n",
    "                           random_state=42)\n",
    "\n",
    "        self.model.fit(X_train, y_train, cat_features=categorical_features)\n",
    "        \n",
    "        return self.estimate(X_test, y_test)\n",
    "    \n",
    "    def label_shuffle(self, X, y, X_ss, y_ss, random_state=42):\n",
    "        X_ss['ss'] = 1\n",
    "        y_ss = y_ss.to_frame()\n",
    "        y_ss['ss'] = 1\n",
    "\n",
    "        X['ss'] = 0\n",
    "        y['ss'] = 0\n",
    "\n",
    "        X_ss_full = pd.concat([X, X_ss]).sample(frac=1, random_state=random_state)\n",
    "        y_ss_full = pd.concat([y, y_ss]).sample(frac=1, random_state=random_state)\n",
    "        \n",
    "        return (X_ss_full, y_ss_full)\n",
    "    \n",
    "    def train_cross_validation(self, X, y, k, categorical_features, X_ss=None, y_ss=None, random_state=42):\n",
    "        chunk_size = len(X) / k\n",
    "        chunks_size = [(i*chunk_size, i*chunk_size + chunk_size) for i in range(k)]\n",
    "        \n",
    "        result_score = []\n",
    "        \n",
    "        print(f\"Part size: {chunk_size}\")\n",
    "        \n",
    "        if (X_ss is not None):\n",
    "            X_ss_full, y_ss_full = self.label_shuffle(X, y, X_ss, y_ss, random_state = random_state)\n",
    "            \n",
    "            for chunkIndex in range(len(chunks_size)):\n",
    "                x_test = X_ss_full[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
    "                y_test = y_ss_full[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
    "                \n",
    "                x_train = X_ss_full.drop(x_test.index, axis = 0)\n",
    "                y_train = y_ss_full.drop(y_test.index, axis = 0)\n",
    "                \n",
    "                x_test = x_test[x_test.ss == 0]\n",
    "                y_test = y_test[y_test.ss == 0]\n",
    "                \n",
    "                x_train.drop('ss', axis = 1, inplace = True)\n",
    "                y_train.drop('ss', axis = 1, inplace = True)\n",
    "                x_test.drop('ss', axis = 1, inplace = True)\n",
    "                y_test.drop('ss', axis = 1, inplace = True)\n",
    "                \n",
    "                score = self.train(x_train, x_test, y_train, y_test, categorical_features)\n",
    "                \n",
    "                print(f\"Chunk {chunkIndex}; Score: {score}\")\n",
    "                \n",
    "                result_score.append((chunks_size[chunkIndex], score))\n",
    "        else:            \n",
    "            for chunkIndex in range(len(chunks_size)):\n",
    "                x_test = X[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
    "                y_test = y[int(chunks_size[chunkIndex][0]) : int(chunks_size[chunkIndex][1])]\n",
    "                \n",
    "                x_train = X.drop(x_test.index, axis = 0)\n",
    "                y_train = y.drop(y_test.index, axis = 0)\n",
    "                \n",
    "                score = self.train(x_train, x_test, y_train, y_test, categorical_features)\n",
    "                \n",
    "                print(f\"Chunk {chunkIndex}; Score: {score}\")\n",
    "                \n",
    "                result_score.append((chunks_size[chunkIndex], score))\n",
    "            \n",
    "        print(f\"Mean score: {sum(list(map(lambda x: x[1], result_score))) / k}\")\n",
    "        \n",
    "        return result_score\n",
    "    \n",
    "    def fit_ss(self, X, y, numeric_features, categorial_features, X_ss, y_ss, cross_validation=False):\n",
    "        self.counter_words = {}\n",
    "        \n",
    "        X_ = X\n",
    "        y_ = y\n",
    "        \n",
    "        self.NLP_preprocess(pd.concat([X_, X_ss]), pd.concat([y_, y_ss]))\n",
    "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
    "        \n",
    "        X_ss = self.add_features(X_ss)[numeric_features + categorical_features]\n",
    "        \n",
    "        if (not cross_validation):\n",
    "            X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, X_ss=X_ss, y_ss=y_ss, random_state=42)\n",
    "            return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
    "        else:\n",
    "            return self.train_cross_validation(X_, y_, 5, categorical_features, X_ss=X_ss, y_ss=y_ss, random_state=42)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, numeric_features, categorial_features, cross_validation=False):\n",
    "        self.counter_words = {}\n",
    "        \n",
    "        X_ = X\n",
    "        y_ = y\n",
    "        \n",
    "        self.NLP_preprocess(X_, y_)\n",
    "        X_ = self.add_features(X_)[numeric_features + categorical_features]\n",
    "\n",
    "        if (not cross_validation):\n",
    "            X_train, X_test, y_train, y_test = self.train_test_split_(X_, y_, test_size=0.2, random_state=42)\n",
    "            return self.train(X_train, X_test, y_train, y_test, categorical_features)\n",
    "        else:\n",
    "            return self.train_cross_validation(X_, y_, 5, categorical_features, random_state=42)\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X, add_feat=True):\n",
    "        if (add_feat): X = self.add_features(X)\n",
    "        \n",
    "        X = X[numeric_features + categorical_features]\n",
    "        \n",
    "        return self.model.predict_proba(X).T[1]\n",
    "    \n",
    "    def predict_thresh(self, X, thresh_above, thresh_below):\n",
    "        y_unlab_full = self.predict_proba(X)\n",
    "        \n",
    "        y_unlab = pd.Series([-1 for i in range(len(X))])\n",
    "        \n",
    "        print(\"Thresh above: {}\".format(sum(y_unlab_full >= thresh_above) / len(y_unlab_full)))\n",
    "        print(\"Thresh below: {}\".format(sum(y_unlab_full <= thresh_below) / len(y_unlab_full)))\n",
    "        \n",
    "        y_unlab.iloc[np.where(y_unlab_full >= thresh_above)] = 1\n",
    "        y_unlab.iloc[np.where(y_unlab_full <= thresh_below)] = 0\n",
    "        \n",
    "        return y_unlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled = pd.read_csv('data/labled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
    "\n",
    "X_ = train_labeled.iloc[:, :-1]\n",
    "y_ = train_labeled.iloc[:, -1:]\n",
    "\n",
    "X_['client_rate_ride'] = X_['client_rate_ride'].fillna(X_['client_rate_ride'].mean())\n",
    "X_['client_rides_cnt'] = X_['client_rides_cnt'].fillna(X_['client_rides_cnt'].mean())\n",
    "X_['driver_rides_cnt'] = X_['driver_rides_cnt'].fillna(X_['driver_rides_cnt'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['distance', 'arrived_distance', 'arrived_duration', 'duration', 'driver_rides_cnt', 'client_rides_cnt', 'client_rate_ride', 'count_words']\n",
    "\n",
    "categorical_features = ['mark', 'is_comment', 'hour', 'weekday', 'agg_words', 'normal_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (7200, 14)\n",
      "Test size: (1800, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8362260536398467"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_supervised = Model()\n",
    "\n",
    "model_supervised.fit(X_, y_, numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part size: 1800.0\n",
      "Train size: (7200, 14)\n",
      "Test size: (1800, 14)\n",
      "Chunk 0; Score: 0.7501325765301662\n",
      "Train size: (7200, 14)\n",
      "Test size: (1800, 14)\n",
      "Chunk 1; Score: 0.7869791274206916\n",
      "Train size: (7200, 14)\n",
      "Test size: (1800, 14)\n",
      "Chunk 2; Score: 0.7333526906697638\n",
      "Train size: (7200, 14)\n",
      "Test size: (1800, 14)\n",
      "Chunk 3; Score: 0.7684012885885325\n",
      "Train size: (7200, 14)\n",
      "Test size: (1800, 14)\n",
      "Chunk 4; Score: 0.7787730470989159\n",
      "Mean score: 0.7635277460616141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((0.0, 1800.0), 0.7501325765301662),\n",
       " ((1800.0, 3600.0), 0.7869791274206916),\n",
       " ((3600.0, 5400.0), 0.7333526906697638),\n",
       " ((5400.0, 7200.0), 0.7684012885885325),\n",
       " ((7200.0, 9000.0), 0.7787730470989159)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv = Model()\n",
    "\n",
    "model_cv.fit(X_, y_, numeric_features, categorical_features, cross_validation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlab = pd.read_csv('data/unlabled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
    "comments_unlabeled = pd.read_csv('data/unlabled_train_comments.csv', index_col=0, sep='\\t', comment='#')\n",
    "tracks_unlabeled = pd.read_csv('data/unlabled_train_tracks.csv', index_col=0, sep='\\t', comment='#')\n",
    "\n",
    "X_unlab['client_rate_ride'] = X_unlab['client_rate_ride'].fillna(X_unlab['client_rate_ride'].mean())\n",
    "X_unlab['client_rides_cnt'] = X_unlab['client_rides_cnt'].fillna(X_unlab['client_rides_cnt'].mean())\n",
    "X_unlab['driver_rides_cnt'] = X_unlab['driver_rides_cnt'].fillna(X_unlab['driver_rides_cnt'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64866629360194"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2762,  3239,  3574, ..., 10719, 10720, 10721])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(X_unlab.comment.isna())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nanIndex in np.where(X_unlab.comment.isna())[0]:\n",
    "    obj_comment = comments_unlabeled.loc[nanIndex]\n",
    "    \n",
    "    if (len(obj_comment) != 0):\n",
    "        X_unlab.comment.iloc[nanIndex] = obj_comment.comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00018653236336504383"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_unlab.comment.isna()) / len(X_unlab.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlab.comment.iloc[np.where(X_unlab.comment.isna())[0]] = \"---\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction&filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh above: 0.0318970341354225\n",
      "Thresh below: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_unlab = model_supervised.predict_thresh(X_unlab, 0.9, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unlab.name = \"is_aggressive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    10380\n",
       " 1      342\n",
       "Name: is_aggressive, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_unlab.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlab_lab = X_unlab.iloc[np.where(y_unlab != -1)]\n",
    "y_unlab_lab = y_unlab.iloc[np.where(y_unlab != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6        Водитель разговаривал по телефону, переписывал...\n",
       "7        1)Водитель играл в «шашки» на дороге и игрался...\n",
       "21       Водитель ковырялся в носу, агрессивное вождени...\n",
       "25                             водитель засыпал за рулём. \n",
       "92                                       опасное вождение \n",
       "                               ...                        \n",
       "10646                    непонятные обгоны, поехал поворот\n",
       "10648               побольше бы таких замечательных людей \n",
       "10669        По встречной ехал, и ударился в другую машину\n",
       "10711    высадил меня прямо посреди большой лужи со сне...\n",
       "10712                              очень долго ждал машину\n",
       "Name: comment, Length: 342, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unlab_lab.comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    342\n",
       "Name: is_comment, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unlab_lab.is_comment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (7474, 14)\n",
      "Test size: (1802, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8300960984898809"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_semisupervised = Model()\n",
    "\n",
    "model_semisupervised.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part size: 1800.0\n",
      "Train size: (7461, 14)\n",
      "Test size: (1734, 14)\n",
      "Chunk 0; Score: 0.7142659067523881\n",
      "Train size: (7449, 14)\n",
      "Test size: (1737, 14)\n",
      "Chunk 1; Score: 0.8066374694564246\n",
      "Train size: (7454, 14)\n",
      "Test size: (1738, 14)\n",
      "Chunk 2; Score: 0.7476913114477166\n",
      "Train size: (7453, 14)\n",
      "Test size: (1723, 14)\n",
      "Chunk 3; Score: 0.7388445839874411\n",
      "Train size: (7462, 14)\n",
      "Test size: (1738, 14)\n",
      "Chunk 4; Score: 0.8023173479240425\n",
      "Mean score: 0.7619513239136025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((0.0, 1800.0), 0.7142659067523881),\n",
       " ((1800.0, 3600.0), 0.8066374694564246),\n",
       " ((3600.0, 5400.0), 0.7476913114477166),\n",
       " ((5400.0, 7200.0), 0.7388445839874411),\n",
       " ((7200.0, 9000.0), 0.8023173479240425)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ss_cv = Model()\n",
    "\n",
    "model_ss_cv.fit_ss(X_, y_, numeric_features, categorical_features, X_unlab_lab, y_unlab_lab, cross_validation = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
