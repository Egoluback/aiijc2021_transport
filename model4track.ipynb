{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
    },
    "colab": {
      "name": "model4track.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Egoluback/aijic2021_transport/blob/yarik/model4track.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Any, Tuple, Union\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from os.path import exists"
      ],
      "outputs": [],
      "metadata": {
        "id": "UBD5ozotX3Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6524d11-3fb6-4a51-884b-182d510925fb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "path = \"./\"\n",
        "\n",
        "train_labeled = pd.read_csv(path + 'data/base_files/labled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "comments_labeled = pd.read_csv(path + 'data/base_files/labled_train_comments.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_labeled = pd.read_csv(path + 'data/labled_train_tracks_speed.csv', index_col=0, sep=',', comment='#')\n",
        "\n",
        "train_unlabeled = pd.read_csv(path +'data/base_files/unlabled_train_data.csv', index_col=0, sep='\\t', comment='#')\n",
        "comments_unlabeled = pd.read_csv(path+ 'data/base_files/unlabled_train_comments.csv', index_col=0, sep='\\t', comment='#')\n",
        "tracks_unlabeled = pd.read_csv(path+ 'data/unlabled_train_tracks_speed.csv', index_col=0, sep=',', comment='#')"
      ],
      "outputs": [],
      "metadata": {
        "id": "-PSrLGdXX3Qy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "tracks_unlabeled"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               driver_id                   dt       lat_  \\\n",
              "0       6bcc649b6ec22251179da12125d04011  2021-03-29 11:55:56  55.757886   \n",
              "1       6bcc649b6ec22251179da12125d04011  2021-03-29 11:56:02  55.757886   \n",
              "2       6bcc649b6ec22251179da12125d04011  2021-03-29 11:56:23  55.758017   \n",
              "3       6bcc649b6ec22251179da12125d04011  2021-03-29 11:56:43  55.757987   \n",
              "4       6bcc649b6ec22251179da12125d04011  2021-03-29 11:57:04  55.758015   \n",
              "...                                  ...                  ...        ...   \n",
              "674713  4cbab2104a47e4ea966c7f2ecd8f4775  2021-03-26 20:44:42  55.656228   \n",
              "674714  4cbab2104a47e4ea966c7f2ecd8f4775  2021-03-26 20:45:04  55.656143   \n",
              "674715  4cbab2104a47e4ea966c7f2ecd8f4775  2021-03-26 20:45:24  55.655037   \n",
              "674716  4cbab2104a47e4ea966c7f2ecd8f4775  2021-03-26 20:45:46  55.654412   \n",
              "674717  4cbab2104a47e4ea966c7f2ecd8f4775  2021-03-26 20:45:47  55.654412   \n",
              "\n",
              "             lon_                          order_id      speed  \n",
              "0       37.406491  0000a57c86cabd27d707a5fde1d0fbe4        NaN  \n",
              "1       37.406491  0000a57c86cabd27d707a5fde1d0fbe4   0.000000  \n",
              "2       37.406500  0000a57c86cabd27d707a5fde1d0fbe4   2.228571  \n",
              "3       37.406500  0000a57c86cabd27d707a5fde1d0fbe4   0.540000  \n",
              "4       37.406495  0000a57c86cabd27d707a5fde1d0fbe4   0.514286  \n",
              "...           ...                               ...        ...  \n",
              "674713  37.494256  fffface895e65d8da177137701b1ee98   0.000000  \n",
              "674714  37.494459  fffface895e65d8da177137701b1ee98   3.600000  \n",
              "674715  37.496817  fffface895e65d8da177137701b1ee98  46.980000  \n",
              "674716  37.498307  fffface895e65d8da177137701b1ee98  26.509091  \n",
              "674717  37.498307  fffface895e65d8da177137701b1ee98   0.000000  \n",
              "\n",
              "[674718 rows x 6 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>driver_id</th>\n",
              "      <th>dt</th>\n",
              "      <th>lat_</th>\n",
              "      <th>lon_</th>\n",
              "      <th>order_id</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:55:56</td>\n",
              "      <td>55.757886</td>\n",
              "      <td>37.406491</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:56:02</td>\n",
              "      <td>55.757886</td>\n",
              "      <td>37.406491</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:56:23</td>\n",
              "      <td>55.758017</td>\n",
              "      <td>37.406500</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>2.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:56:43</td>\n",
              "      <td>55.757987</td>\n",
              "      <td>37.406500</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>0.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:57:04</td>\n",
              "      <td>55.758015</td>\n",
              "      <td>37.406495</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674713</th>\n",
              "      <td>4cbab2104a47e4ea966c7f2ecd8f4775</td>\n",
              "      <td>2021-03-26 20:44:42</td>\n",
              "      <td>55.656228</td>\n",
              "      <td>37.494256</td>\n",
              "      <td>fffface895e65d8da177137701b1ee98</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674714</th>\n",
              "      <td>4cbab2104a47e4ea966c7f2ecd8f4775</td>\n",
              "      <td>2021-03-26 20:45:04</td>\n",
              "      <td>55.656143</td>\n",
              "      <td>37.494459</td>\n",
              "      <td>fffface895e65d8da177137701b1ee98</td>\n",
              "      <td>3.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674715</th>\n",
              "      <td>4cbab2104a47e4ea966c7f2ecd8f4775</td>\n",
              "      <td>2021-03-26 20:45:24</td>\n",
              "      <td>55.655037</td>\n",
              "      <td>37.496817</td>\n",
              "      <td>fffface895e65d8da177137701b1ee98</td>\n",
              "      <td>46.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674716</th>\n",
              "      <td>4cbab2104a47e4ea966c7f2ecd8f4775</td>\n",
              "      <td>2021-03-26 20:45:46</td>\n",
              "      <td>55.654412</td>\n",
              "      <td>37.498307</td>\n",
              "      <td>fffface895e65d8da177137701b1ee98</td>\n",
              "      <td>26.509091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674717</th>\n",
              "      <td>4cbab2104a47e4ea966c7f2ecd8f4775</td>\n",
              "      <td>2021-03-26 20:45:47</td>\n",
              "      <td>55.654412</td>\n",
              "      <td>37.498307</td>\n",
              "      <td>fffface895e65d8da177137701b1ee98</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>674718 rows Ã— 6 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "RiDUIy40nlsu",
        "outputId": "99fd7bf4-f14d-44bd-9a12-a4c5acc08b57"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "tracks_unlabeled.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          driver_id                   dt       lat_  \\\n",
              "0  6bcc649b6ec22251179da12125d04011  2021-03-29 11:55:56  55.757886   \n",
              "1  6bcc649b6ec22251179da12125d04011  2021-03-29 11:56:02  55.757886   \n",
              "2  6bcc649b6ec22251179da12125d04011  2021-03-29 11:56:23  55.758017   \n",
              "3  6bcc649b6ec22251179da12125d04011  2021-03-29 11:56:43  55.757987   \n",
              "4  6bcc649b6ec22251179da12125d04011  2021-03-29 11:57:04  55.758015   \n",
              "\n",
              "        lon_                          order_id     speed  \n",
              "0  37.406491  0000a57c86cabd27d707a5fde1d0fbe4       NaN  \n",
              "1  37.406491  0000a57c86cabd27d707a5fde1d0fbe4  0.000000  \n",
              "2  37.406500  0000a57c86cabd27d707a5fde1d0fbe4  2.228571  \n",
              "3  37.406500  0000a57c86cabd27d707a5fde1d0fbe4  0.540000  \n",
              "4  37.406495  0000a57c86cabd27d707a5fde1d0fbe4  0.514286  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>driver_id</th>\n",
              "      <th>dt</th>\n",
              "      <th>lat_</th>\n",
              "      <th>lon_</th>\n",
              "      <th>order_id</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:55:56</td>\n",
              "      <td>55.757886</td>\n",
              "      <td>37.406491</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:56:02</td>\n",
              "      <td>55.757886</td>\n",
              "      <td>37.406491</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:56:23</td>\n",
              "      <td>55.758017</td>\n",
              "      <td>37.406500</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>2.228571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:56:43</td>\n",
              "      <td>55.757987</td>\n",
              "      <td>37.406500</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>0.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6bcc649b6ec22251179da12125d04011</td>\n",
              "      <td>2021-03-29 11:57:04</td>\n",
              "      <td>55.758015</td>\n",
              "      <td>37.406495</td>\n",
              "      <td>0000a57c86cabd27d707a5fde1d0fbe4</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "id": "tir81tvuX3Q0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "4e85dea6-e0d4-4ca5-fab8-e922a8c521b6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "each order is different batch"
      ],
      "metadata": {
        "id": "fi10wdSXX3Q2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "class Preprocessing_labeled():\n",
        "    def __init__(self, tracks_labeled,  chunk_size=15, multiplier=1):\n",
        "        self.tracks = tracks_labeled\n",
        "        self.MULTIPLIER = multiplier\n",
        "        self.CHUNK_SIZE = chunk_size\n",
        "\n",
        "    # undersampling method deletes some extra non aggressive values\n",
        "    def undersampling(self, X):\n",
        "        aggressive_count = sum(X.is_aggressive == 1)\n",
        "        non_aggressive_ind = X[X.is_aggressive == 0].index\n",
        "\n",
        "        # keep aggressive_count*multiplier number of non_aggressive samples\n",
        "        random_indices = np.random.choice(\n",
        "            non_aggressive_ind, aggressive_count*self.MULTIPLIER, replace=False)\n",
        "        return pd.concat([X.loc[random_indices], X[X.is_aggressive == 1]])\n",
        "\n",
        "    def split(self, arr, chunk_size=15):\n",
        "        result = []\n",
        "        # get right length of arr so that it equally splits into chunks\n",
        "        length = len(arr)\n",
        "        split_length = length - (length % self.CHUNK_SIZE)\n",
        "\n",
        "        for i in range(split_length)[self.CHUNK_SIZE::self.CHUNK_SIZE]:\n",
        "            result.append(arr[i-self.CHUNK_SIZE:i])\n",
        "\n",
        "        return np.array(result)\n",
        "\n",
        "    # make df, so that each row has Series object with order speeds\n",
        "    def make_nested(self, tracks,):\n",
        "        copied_tracks = tracks.copy()\n",
        "        orders = copied_tracks.drop_duplicates('order_id', keep='last')\n",
        "        orders = self.undersampling(orders)\n",
        "\n",
        "        y_labels = []\n",
        "        X_train = []\n",
        "        for order in tqdm(orders['order_id']):\n",
        "            order_df = copied_tracks[copied_tracks.order_id == order]\n",
        "            order_df.loc[0, 'speed'] = 0\n",
        "\n",
        "            if order_df.shape[0] < self.CHUNK_SIZE:\n",
        "                continue\n",
        "\n",
        "            splitted_arrs = self.split(order_df.values, self.CHUNK_SIZE)\n",
        "            for arr in splitted_arrs:\n",
        "                is_aggressive = arr[0][7]\n",
        "                y_labels.append(is_aggressive)\n",
        "                speed_series = []\n",
        "                for row in arr:  \n",
        "                    # append only speed \n",
        "                    speed_series.append(row[6])\n",
        "                X_train.append(pd.Series(speed_series))\n",
        "\n",
        "        return X_train, y_labels"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES6yLStFX3Q3",
        "outputId": "6a2103dc-49b9-4913-bf43-ce68f4d22d6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "\n",
        "class Preprocessing_unlabeled():\n",
        "    def __init__(self, tracks_unlabeled, chunk_size=15, multiplier=1):\n",
        "        self.CHUNK_SIZE = chunk_size\n",
        "        self.MULTIPLIER = multiplier\n",
        "        self.tracks = tracks_unlabeled\n",
        "\n",
        "    def split(self, arr,):\n",
        "        result = []\n",
        "        # get right length of arr so that it equally splits into chunks\n",
        "        length = len(arr)\n",
        "        split_length = length - (length % self.CHUNK_SIZE)\n",
        "\n",
        "        for i in range(split_length)[self.CHUNK_SIZE::self.CHUNK_SIZE]:\n",
        "            result.append(arr[i-self.CHUNK_SIZE:i])\n",
        "\n",
        "        return np.array(result)\n",
        "\n",
        "    # undersampling method deletes extra non aggressive values\n",
        "    def undersampling(self, X, y):\n",
        "        aggressive_count = np.sum(y)\n",
        "        non_aggressive_ind = np.argwhere(y == 0.0).flatten()\n",
        "        aggressive_ind = np.argwhere(y == 1.0).flatten()\n",
        "        # keep aggressive_count*multiplier number of non_aggressive samples\n",
        "        random_indices = np.random.choice(\n",
        "            non_aggressive_ind, int(aggressive_count)*self.MULTIPLIER, replace=False)\n",
        "        print(random_indices)\n",
        "        undersampling_X = np.concatenate(\n",
        "            [np.take(X, random_indices, 0), \n",
        "             np.take(X, aggressive_ind, 0)])\n",
        "        undersampling_y = np.concatenate(\n",
        "            [np.take(y, aggressive_ind), \n",
        "             np.take(y, random_indices)])\n",
        "        return undersampling_X, undersampling_y\n",
        "\n",
        "    # make df, so that each row has Series object with order speeds\n",
        "    def make_nested(self, tracks):\n",
        "        orders = tracks.drop_duplicates('order_id', keep='last')\n",
        "\n",
        "        X_train = []\n",
        "        for order in tqdm(orders['order_id']):\n",
        "            order_df = tracks[tracks.order_id == order]\n",
        "            order_df.loc[0, 'speed'] = 0\n",
        "\n",
        "            if order_df.shape[0] < self.CHUNK_SIZE:\n",
        "                continue\n",
        "            \n",
        "            splitted_arrs = self.split(order_df.values)\n",
        "            for arr in splitted_arrs:\n",
        "                \n",
        "                speed_series = []\n",
        "                for row in arr:\n",
        "                    # append only speed\n",
        "                    speed_series.append(row[5])\n",
        "                X_train.append(pd.Series(speed_series))\n",
        "\n",
        "        return pd.DataFrame({'speed': X_train})\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "vjkfOwV9SXmm",
        "outputId": "adebdef7-845d-4c9b-8e59-d45d91e5c695"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "testing = \"dummy\"\n",
        "testing2 = \"dummy\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sktime.transformations.panel.rocket import MiniRocket\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "import sklearn.linear_model\n",
        "import json\n",
        "\n",
        "#Classifier = Union[LogisticRegressionCV,\n",
        "#                   LogisticRegressionCV, RidgeClassifier, RidgeClassifierCV]\n",
        "\n",
        "class Model4track():\n",
        "    def __init__(self, train_labeled, tracks_labeled, tracks_unlabeled, labeled_trained_model_path, semisupervised_model_path, get_score=True):\n",
        "        self.rocket = MiniRocket()\n",
        "        self.get_score = get_score\n",
        "        self.train_labeled = train_labeled\n",
        "        self.tracks_unlabeled = tracks_unlabeled\n",
        "        self.tracks_labeled = tracks_labeled\n",
        "        self.preprocessing_unlabeled = Preprocessing_unlabeled(\n",
        "            self.tracks_unlabeled,15,1)\n",
        "        self.preprocessing_labeled = Preprocessing_labeled(\n",
        "            self.tracks_labeled,15,1)\n",
        "        self.labled_trained_model_path = labeled_trained_model_path \n",
        "        self.semisupervised_model_path = semisupervised_model_path \n",
        "\n",
        "    def train(self, X_train_transform, y_train, X_test_transform, y_test):\n",
        "\n",
        "        classifier = RidgeClassifier(normalize=True)\n",
        "        if self.get_score:\n",
        "            classifier = RidgeClassifierCV(normalize=True)\n",
        "        classifier.fit(X_train_transform, y_train)\n",
        "        with open(self.semisupervised_model_path, 'wb+') as file:\n",
        "            pickle.dump(classifier, file)\n",
        "        if self.get_score:\n",
        "            print(\"________________SCORE____________________\")\n",
        "            print(classifier.score(X_test_transform, y_test))\n",
        "\n",
        "        return classifier\n",
        "\n",
        "    def ss_train(self) -> sklearn.linear_model:\n",
        "        '''\n",
        "        Semi-supervised training algorithm. We train classifier on our labeled data, \n",
        "        then use this classifier to label unlabeled data \n",
        "        and retrain classifier on this pseudo-labeled data \n",
        "        ''' \n",
        "        def convert(x):\n",
        "            if hasattr(x, \"tolist\"):  # numpy arrays have this\n",
        "                return {\"$array\": x.tolist()}  # Make a tagged object\n",
        "            raise TypeError(x)\n",
        "\n",
        "        def deconvert(x):\n",
        "            if len(x) == 1:  # Might be a tagged object...\n",
        "                key, value = next(iter(x.items()))  # Grab the tag and value\n",
        "                if key == \"$array\":  # If the tag is correct,\n",
        "                    return np.array(value)  # cast back to array\n",
        "            return x\n",
        "\n",
        "        cached_data_path = 'data/labeled_preprocessed.json'\n",
        "        cached_y_data_path = 'data/labeled_y_preprocessed.json'\n",
        "        if exists(cached_data_path):\n",
        "            with open(cached_data_path) as X_file, open(cached_y_data_path) as y_file:\n",
        "                X_train = np.array(json.load(X_file, object_hook=deconvert))\n",
        "                X_train = [pd.Series(arr) for arr in X_train]\n",
        "                y_train = json.load(y_file, object_hook=deconvert)\n",
        "        else:\n",
        "            X_train, y_train = self.preprocessing_labeled.make_nested(self.tracks_labeled)\n",
        "            with open(cached_data_path, 'w') as X_file, open(cached_y_data_path, 'w') as y_file:\n",
        "                json.dump(X_train, X_file, default=convert)\n",
        "                json.dump(y_train, y_file, default=convert)\n",
        "\n",
        "        if self.get_score:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_train, y_train, test_size=0.33)\n",
        "            X_test = pd.DataFrame({'speed':X_test})\n",
        "            y_test = np.array(y_test)\n",
        "        \n",
        "        X_train = pd.DataFrame({'speed':X_train})\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        # training classifier on labeled data\n",
        "        self.rocket.fit(X_train)\n",
        "        X_train_transform = self.rocket.transform(X_train)\n",
        "        if self.get_score:\n",
        "            X_test_transform = self.rocket.transform(X_test)\n",
        "\n",
        "        # check if pretrained model exists\n",
        "        if not exists(self.labled_trained_model_path):\n",
        "                        \n",
        "            classifier = self.train(\n",
        "                X_train_transform, y_train, X_test_transform, y_test)\n",
        "\n",
        "            with open(self.labled_trained_model_path ,mode='wb') as file:\n",
        "                pickle.dump(classifier, file)\n",
        "        else:\n",
        "            with open(self.labled_trained_model_path ,mode='rb') as file:\n",
        "                classifier = pickle.load(file)\n",
        "\n",
        "        # unsupervised learning\n",
        "        unlabled_preprocessed_path = './data/pseudo_X.json'\n",
        "        if exists(unlabled_preprocessed_path):\n",
        "            with open(unlabled_preprocessed_path) as file:\n",
        "                pseudo_X = json.load(file, object_hook=deconvert)\n",
        "        else:\n",
        "            pseudo_X = self.preprocessing_unlabeled.make_nested(self.tracks_unlabeled)\n",
        "            with open(unlabled_preprocessed_path, 'w') as file:\n",
        "                json.dump(pseudo_X.to_numpy(), file, default = convert)\n",
        "\n",
        "\n",
        "        #pseudo_X = pd.DataFrame(pseudo_X)\n",
        "        print(pseudo_X)\n",
        "\n",
        "        self.rocket.fit(pseudo_X)\n",
        "        transformed_pseudo_X = self.rocket.transform(pseudo_X)\n",
        "        pseudo_y = classifier.predict(transformed_pseudo_X)\n",
        "\n",
        "        # if number of aggressive samples less than non agressive\n",
        "        if sum(pseudo_y)<len(pseudo_y)/2:\n",
        "            pseudo_X, pseudo_y = self.preprocessing_unlabeled.undersampling(pseudo_X, pseudo_y)\n",
        "\n",
        "        all_X_transform = pd.concat([transformed_pseudo_X, X_train_transform])\n",
        "        all_y = np.concatenate((pseudo_y, y_train))\n",
        "        print('SHAPE')\n",
        "        print(len(all_X_transform))\n",
        "        print('AGGRESSIVE PERCENTAGE')\n",
        "        print(all_y.sum()/len(all_y))\n",
        "\n",
        "        \n",
        "        semisupervised_classifer = self.train(all_X_transform, all_y, X_test_transform, y_test) \n",
        "        with open(self.semisupervised_model_path, 'wb+') as file:\n",
        "            pickle.dump(semisupervised_classifer, file)\n",
        "        return semisupervised_classifer\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "fsf8qxg6X3Q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d1f52d-a47e-44ff-aedf-6e90693cc8fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-training realization:\n",
        "1. Make pseudo-labels for unlabled data\n",
        "2. Retrain classifier on labled and pseudolabled data\n",
        "https://towardsdatascience.com/a-gentle-introduction-to-self-training-and-semi-supervised-learning-ceee73178b38 "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "\n",
        "labeled_trained_model_path = './models/labeled_trained_classifier.pkl'\n",
        "semisupervised_model_path = './models/semisupervised_classifier.pkl'\n",
        "model = Model4track(train_labeled, tracks_labeled, tracks_unlabeled, labeled_trained_model_path, semisupervised_model_path)\n",
        "model.ss_train()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[  0.           0.           2.22857143 ...   7.88571429   5.70731707\n",
            "    49.4557377 ]]\n",
            "\n",
            " [[  0.          89.1          0.         ...  31.07368421  43.37142857\n",
            "    39.6       ]]\n",
            "\n",
            " [[  5.48571429   3.51         7.92       ... 129.22105263 121.32\n",
            "   107.82857143]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[  0.           1.06363636  10.6        ...   0.          28.28571429\n",
            "     0.        ]]\n",
            "\n",
            " [[  0.           2.74285714   0.         ... 103.71428571 100.50967742\n",
            "   103.24285714]]\n",
            "\n",
            " [[  0.         106.81967213  88.74782609 ...  44.57142857  63.74117647\n",
            "    49.24285714]]]\n",
            "[ 2663  8402  6430 ...  9264 17978  6959]\n",
            "SHAPE\n",
            "32216\n",
            "AGGRESSIVE PERCENTAGE\n",
            "0.5015062567588444\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [32216, 25892]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-506187f72424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msemisupervised_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./models/semisupervised_classifier.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel4track\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_trained_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemisupervised_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mss_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-44142262f0e0>\u001b[0m in \u001b[0;36mss_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0msemisupervised_classifer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_X_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemisupervised_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemisupervised_classifer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-44142262f0e0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train_transform, y_train, X_test_transform, y_test)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidgeClassifierCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemisupervised_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1940\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \"\"\"\n\u001b[0;32m-> 1942\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m   1943\u001b[0m                                    multi_output=True, y_numeric=False)\n\u001b[1;32m   1944\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [32216, 25892]"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "lwCl8sYW5_Ed",
        "outputId": "c2df0a83-9f90-46dd-f4b3-d91a86b299e6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "classifier = None\n",
        "\n",
        "preprocessing_labeled = Preprocessing_labeled(\n",
        "    tracks_labeled,15,1)\n",
        "#X_train, y_train = preprocessing_labeled.make_nested(tracks_labeled)\n",
        "\n",
        "cached_data_path = 'data/labeled_preprocessed.json'\n",
        "cached_y_data_path = 'data/labeled_y_preprocessed.json'\n",
        "def deconvert(x):\n",
        "    if len(x) == 1:  # Might be a tagged object...\n",
        "        key, value = next(iter(x.items()))  # Grab the tag and value\n",
        "        if key == \"$array\":  # If the tag is correct,\n",
        "            return np.array(value)  # cast back to array\n",
        "    return x\n",
        "\n",
        "with open(cached_data_path) as X_file, open(cached_y_data_path) as y_file:\n",
        "                X_train = np.array(json.load(X_file, object_hook=deconvert))\n",
        "                X_train = [pd.Series(arr) for arr in X_train]\n",
        "                y_train = json.load(y_file, object_hook=deconvert)\n",
        "print(1)                \n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_train, y_train, test_size=0.33)\n",
        "X_test = pd.DataFrame({'speed':X_test})\n",
        "print(X_test.describe())\n",
        "y_test = np.array(y_test)\n",
        "print(y_test.shape)\n",
        "X_train = pd.DataFrame({'speed':X_train})\n",
        "print(2)                \n",
        "rocket = MiniRocket()\n",
        "rocket.fit(X_train)\n",
        "X_test_transform = rocket.transform(X_test)\n",
        "print(3)                \n",
        "\n",
        "with open('./models/semisupervised_classifier.pkl',mode='rb') as file:\n",
        "    classifier = pickle.load(file)\n",
        "classifier.score(X_test_transform, y_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "testing3 = None"
      ],
      "outputs": [],
      "metadata": {
        "id": "ybyyvgtjX3Q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5870a4b0-d0dc-4d1c-f1a7-dae8d2e80f5e"
      }
    }
  ]
}